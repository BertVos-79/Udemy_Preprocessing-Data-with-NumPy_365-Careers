{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Data with NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### np.loadtxt() vs np.genfromtxt()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 ways of importing CSV-files:\n",
    "\n",
    "1. np.loadtxt()\n",
    "\n",
    "    - data only needs to be 'loaded' for use: data can be directly imported and used\n",
    "    - faster, but less flexibility\n",
    "\n",
    "2. np.genfromtxt()\n",
    "\n",
    "    - dataset needs to be 'generated': data needs to be put in array while going through text file\n",
    "    - slower, more flexibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2000.,    40.,   365.,  3121.,  4241., 13621.],\n",
       "       [ 2000.,    40.,   365.,  3061.,  4171., 15041.],\n",
       "       [ 1000.,    40.,   365.,  2160.,  3280., 15340.],\n",
       "       ...,\n",
       "       [ 2000.,    40.,   365.,  4201.,  5001., 16600.],\n",
       "       [ 1000.,    40.,   365.,  2080.,  3320., 15600.],\n",
       "       [ 2000.,    40.,   365.,  4601.,  4601., 16600.]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lending_co_data_numeric_1 = np.loadtxt(\"Lending-Company-Numeric-Data.csv\", delimiter = ',')\n",
    "lending_co_data_numeric_1\n",
    "\n",
    "# We can use Notepad++ to determine delimiters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2000.,    40.,   365.,  3121.,  4241., 13621.],\n",
       "       [ 2000.,    40.,   365.,  3061.,  4171., 15041.],\n",
       "       [ 1000.,    40.,   365.,  2160.,  3280., 15340.],\n",
       "       ...,\n",
       "       [ 2000.,    40.,   365.,  4201.,  5001., 16600.],\n",
       "       [ 1000.,    40.,   365.,  2080.,  3320., 15600.],\n",
       "       [ 2000.,    40.,   365.,  4601.,  4601., 16600.]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lending_co_data_numeric_2 = np.genfromtxt(\"Lending-Company-Numeric-Data.csv\", delimiter = ',')\n",
    "lending_co_data_numeric_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array_equal(lending_co_data_numeric_1, lending_co_data_numeric_2)\n",
    "\n",
    "## np.array_equal() compares 2 (or more) arrays and tells us if whether they're identical\n",
    "# True = both are the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string '' to float64 at row 11, column 4.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m lending_co_data_numeric_NAN \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloadtxt\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mLending-Company-Numeric-Data-NAN.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdelimiter\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m;\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m lending_co_data_numeric_NAN\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# np.loadtxt() faster but less flexible:\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# ex: np.loadtxt() fails to import incomplete datasets/missing values/NAN by default\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/Udemy_NumPy/lib/python3.13/site-packages/numpy/lib/_npyio_impl.py:1397\u001b[0m, in \u001b[0;36mloadtxt\u001b[0;34m(fname, dtype, comments, delimiter, converters, skiprows, usecols, unpack, ndmin, encoding, max_rows, quotechar, like)\u001b[0m\n\u001b[1;32m   1394\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(delimiter, \u001b[38;5;28mbytes\u001b[39m):\n\u001b[1;32m   1395\u001b[0m     delimiter \u001b[38;5;241m=\u001b[39m delimiter\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlatin1\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m-> 1397\u001b[0m arr \u001b[38;5;241m=\u001b[39m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcomment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcomment\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdelimiter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdelimiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1398\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconverters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconverters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskiplines\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskiprows\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43musecols\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43musecols\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1399\u001b[0m \u001b[43m            \u001b[49m\u001b[43munpack\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munpack\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mndmin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mndmin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1400\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmax_rows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_rows\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquote\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquotechar\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1402\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m arr\n",
      "File \u001b[0;32m/opt/anaconda3/envs/Udemy_NumPy/lib/python3.13/site-packages/numpy/lib/_npyio_impl.py:1036\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(fname, delimiter, comment, quote, imaginary_unit, usecols, skiplines, max_rows, converters, ndmin, unpack, dtype, encoding)\u001b[0m\n\u001b[1;32m   1033\u001b[0m     data \u001b[38;5;241m=\u001b[39m _preprocess_comments(data, comments, encoding)\n\u001b[1;32m   1035\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m read_dtype_via_object_chunks \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1036\u001b[0m     arr \u001b[38;5;241m=\u001b[39m \u001b[43m_load_from_filelike\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1037\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdelimiter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdelimiter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcomment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcomment\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquote\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquote\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1038\u001b[0m \u001b[43m        \u001b[49m\u001b[43mimaginary_unit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimaginary_unit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1039\u001b[0m \u001b[43m        \u001b[49m\u001b[43musecols\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43musecols\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskiplines\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskiplines\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_rows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_rows\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1040\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconverters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconverters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1041\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilelike\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilelike\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1042\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbyte_converters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbyte_converters\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1044\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1045\u001b[0m     \u001b[38;5;66;03m# This branch reads the file into chunks of object arrays and then\u001b[39;00m\n\u001b[1;32m   1046\u001b[0m     \u001b[38;5;66;03m# casts them to the desired actual dtype.  This ensures correct\u001b[39;00m\n\u001b[1;32m   1047\u001b[0m     \u001b[38;5;66;03m# string-length and datetime-unit discovery (like `arr.astype()`).\u001b[39;00m\n\u001b[1;32m   1048\u001b[0m     \u001b[38;5;66;03m# Due to chunking, certain error reports are less clear, currently.\u001b[39;00m\n\u001b[1;32m   1049\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m filelike:\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string '' to float64 at row 11, column 4."
     ]
    }
   ],
   "source": [
    "lending_co_data_numeric_NAN = np.loadtxt(\"Lending-Company-Numeric-Data-NAN.csv\", delimiter = ';')\n",
    "lending_co_data_numeric_NAN\n",
    "\n",
    "\n",
    "# np.loadtxt() faster but less flexible:\n",
    "# ex: np.loadtxt() fails to import incomplete datasets/missing values/NAN by default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2000.,    40.,   365.,  3121.,  4241., 13621.],\n",
       "       [ 2000.,    40.,   365.,  3061.,  4171., 15041.],\n",
       "       [ 1000.,    40.,   365.,  2160.,  3280., 15340.],\n",
       "       ...,\n",
       "       [   nan,    40.,   365.,  4201.,  5001., 16600.],\n",
       "       [ 1000.,    40.,   365.,  2080.,  3320., 15600.],\n",
       "       [ 2000.,    40.,   365.,  4601.,  4601., 16600.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can solve issue in 2 ways:\n",
    "\n",
    "# 1) by using np.genfromtxt()\n",
    "\n",
    "lending_co_data_numeric_NAN = np.genfromtxt(\"Lending-Company-Numeric-Data-NAN.csv\", delimiter = ';')\n",
    "lending_co_data_numeric_NAN\n",
    "\n",
    "# we see 'nan' where it did not find numeric value\n",
    "# np.genfromtxt() works well with missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['2000', '40', '365', '3121', '4241', '13621'],\n",
       "       ['2000', '40', '365', '3061', '4171', '15041'],\n",
       "       ['1000', '40', '365', '2160', '3280', '15340'],\n",
       "       ...,\n",
       "       ['', '40', '365', '4201', '5001', '16600'],\n",
       "       ['1000', '40', '365', '2080', '3320', '15600'],\n",
       "       ['2000', '40', '365', '4601', '4601', '16600']], dtype='<U5')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2) keep using np.loadtxt() but ask Python to import everything as symbols instead of as numbers\n",
    "# concretely this is done by adding argument 'dtype = np.str_'\n",
    "# means we can check all our data, but cannot execute computations\n",
    "\n",
    "lending_co_data_numeric_NAN = np.loadtxt(\"Lending-Company-Numeric-Data-NAN.csv\", \n",
    "                                         delimiter = ';',\n",
    "                                         dtype = np.str_)\n",
    "lending_co_data_numeric_NAN\n",
    "\n",
    "# If we import all the values as text, then we don't get a type inconcsistency, so we can use np.loadtxt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'200040'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lending_co_data_numeric_NAN[0,0] + lending_co_data_numeric_NAN[0,1]\n",
    "\n",
    "# Adding '2000' and '40' results in a concatenated '200040' rather than 2040"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Partial Cleaning While Importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2000.,    40.,   365.,  3121.,  4241., 13621.],\n",
       "       [ 2000.,    40.,   365.,  3061.,  4171., 15041.],\n",
       "       [ 1000.,    40.,   365.,  2160.,  3280., 15340.],\n",
       "       ...,\n",
       "       [   nan,    40.,   365.,  4201.,  5001., 16600.],\n",
       "       [ 1000.,    40.,   365.,  2080.,  3320., 15600.],\n",
       "       [ 2000.,    40.,   365.,  4601.,  4601., 16600.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lending_co_data_numeric_NAN = np.genfromtxt(\"Lending-Company-Numeric-Data-NAN.csv\", delimiter = ';') \n",
    "lending_co_data_numeric_NAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1000.,    40.,   365.,  2160.,  3280., 15340.],\n",
       "       [ 2000.,    40.,   365.,  3041.,  4241., 15321.],\n",
       "       [ 2000.,    50.,   365.,  3470.,  4820., 13720.],\n",
       "       ...,\n",
       "       [   nan,    40.,   365.,  4201.,  5001., 16600.],\n",
       "       [ 1000.,    40.,   365.,  2080.,  3320., 15600.],\n",
       "       [ 2000.,    40.,   365.,  4601.,  4601., 16600.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lending_co_data_numeric_NAN = np.genfromtxt(\"Lending-Company-Numeric-Data-NAN.csv\", \n",
    "                                            delimiter = ';',\n",
    "                                            skip_header = 2) \n",
    "lending_co_data_numeric_NAN\n",
    "\n",
    "# skip_header omits first 2 ROWS from the top of the text file\n",
    "# many different parameters to tweak how you want to import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2000.,    40.,   365.,  3121.,  4241., 13621.],\n",
       "       [ 2000.,    40.,   365.,  3061.,  4171., 15041.],\n",
       "       [ 1000.,    40.,   365.,  2160.,  3280., 15340.],\n",
       "       ...,\n",
       "       [ 2000.,    40.,   365.,  3401.,    nan, 16600.],\n",
       "       [ 2000.,    40.,   365.,    nan,  5440., 16600.],\n",
       "       [   nan,    40.,   365.,  4201.,  5001., 16600.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lending_co_data_numeric_NAN = np.genfromtxt(\"Lending-Company-Numeric-Data-NAN.csv\", \n",
    "                                            delimiter = ';',\n",
    "                                            skip_footer = 2) \n",
    "lending_co_data_numeric_NAN\n",
    "\n",
    "# skip_footer omits 2 ROWS from the bottom of the text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[13621.,  2000.,    40.],\n",
       "       [15041.,  2000.,    40.],\n",
       "       [15340.,  1000.,    40.],\n",
       "       ...,\n",
       "       [16600.,    nan,    40.],\n",
       "       [15600.,  1000.,    40.],\n",
       "       [16600.,  2000.,    40.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lending_co_data_numeric_NAN = np.genfromtxt(\"Lending-Company-Numeric-Data-NAN.csv\", \n",
    "                                            delimiter = ';',\n",
    "                                            usecols = (5,0,1)) \n",
    "lending_co_data_numeric_NAN\n",
    "\n",
    "# use_cols tells the function to only take the following COLUMNS based on their indices\n",
    "# we can specify the order in which we want the columns to appear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[15340.,  1000.,    40.],\n",
       "       [15321.,  2000.,    40.],\n",
       "       [13720.,  2000.,    50.],\n",
       "       ...,\n",
       "       [16600.,  2000.,    40.],\n",
       "       [16600.,  2000.,    40.],\n",
       "       [16600.,    nan,    40.]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lending_co_data_numeric_NAN = np.genfromtxt(\"Lending-Company-Numeric-Data-NAN.csv\", \n",
    "                                            delimiter = ';',\n",
    "                                            usecols = (5,0,1), \n",
    "                                            skip_header = 2, \n",
    "                                            skip_footer = 2) \n",
    "lending_co_data_numeric_NAN\n",
    "\n",
    "# We can define all these arguments (and many more) together to only import what we want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15340. 15321. 13720. ... 16600. 16600. 16600.]\n",
      "[1000. 2000. 2000. ... 2000. 2000.   nan]\n",
      "[40. 40. 50. ... 40. 40. 40.]\n"
     ]
    }
   ],
   "source": [
    "lending_co_data_5, lending_co_data_0, lending_co_data_1 = np.genfromtxt(\"Lending-Company-Numeric-Data-NAN.csv\", \n",
    "                                                                        delimiter = ';',\n",
    "                                                                        usecols = (5,0,1), \n",
    "                                                                        skip_header = 2, \n",
    "                                                                        skip_footer = 2, \n",
    "                                                                        unpack = True)\n",
    "print(lending_co_data_5)\n",
    "print(lending_co_data_0)\n",
    "print(lending_co_data_1)\n",
    "\n",
    "# Unpacking allows us to split the output array into smaller 1-D arrays\n",
    "# order of names and order of outputted columns should be same"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "### String vs Object vs Numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[      nan       nan       nan ...       nan       nan       nan]\n",
      " [1.000e+00       nan       nan ...       nan       nan 1.660e+04]\n",
      " [2.000e+00       nan       nan ...       nan       nan 1.660e+04]\n",
      " ...\n",
      " [1.041e+03       nan       nan ...       nan       nan 1.660e+04]\n",
      " [1.042e+03       nan       nan ...       nan       nan 1.560e+04]\n",
      " [1.043e+03       nan       nan ...       nan       nan 1.660e+04]]\n"
     ]
    }
   ],
   "source": [
    "# The same dataset is imported differently based on the datatype we define\n",
    "\n",
    "# way 1: default, non-numerical values rendered in np.genfromtxt as 'nan'\n",
    "\n",
    "lending_co_lt = np.genfromtxt(\"lending-co-LT.csv\", \n",
    "                              delimiter = ',')\n",
    "print(lending_co_lt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   -1    -1    -1 ...    -1    -1    -1]\n",
      " [    1    -1    -1 ...    -1    -1 16600]\n",
      " [    2    -1    -1 ...    -1    -1 16600]\n",
      " ...\n",
      " [ 1041    -1    -1 ...    -1    -1 16600]\n",
      " [ 1042    -1    -1 ...    -1    -1 15600]\n",
      " [ 1043    -1    -1 ...    -1    -1 16600]]\n"
     ]
    }
   ],
   "source": [
    "# way 2: rendered as integer the 'nan' values are transformed into -1, while scientific notation is rendered as int\n",
    "# therefore: watch out when doing computations on a preprocessed dataset with missing values!\n",
    "\n",
    "lending_co_lt = np.genfromtxt(\"lending-co-LT.csv\", \n",
    "                              delimiter = ',',\n",
    "                              dtype = np.int32\n",
    "                              #dtype = np.float16\n",
    "                              #dtype = np.str_\n",
    "                              #dtype = np.object\n",
    "                              #dtype = (np.int32, np.str_, np.str_, np.str_, np.str_, np.str_, np.int32)\n",
    "                             )\n",
    "print(lending_co_lt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['LoanID' 'StringID' 'Product' ... 'Location' 'Region' 'TotalPrice']\n",
      " ['1' 'id_1' 'Product B' ... 'Location 2' 'Region 2' '16600.0']\n",
      " ['2' 'id_2' 'Product B' ... 'Location 3' '' '16600.0']\n",
      " ...\n",
      " ['1041' 'id_1041' 'Product B' ... 'Location 23' 'Region 4' '16600.0']\n",
      " ['1042' 'id_1042' 'Product C' ... 'Location 52' 'Region 6' '15600.0']\n",
      " ['1043' 'id_1043' 'Product B' ... 'Location 142' 'Region 6' '16600.0']]\n"
     ]
    }
   ],
   "source": [
    "# way 3: rendered as string\n",
    "# becomes clear why the 'nan' values could not be interpreted as numeric values\n",
    "\n",
    "lending_co_lt = np.genfromtxt(\"lending-co-LT.csv\", \n",
    "                              delimiter = ',',\n",
    "                              #dtype = np.int32\n",
    "                              #dtype = np.float16\n",
    "                              dtype = np.str_\n",
    "                              #dtype = np.object\n",
    "                              #dtype = (np.int32, np.str_, np.str_, np.str_, np.str_, np.str_, np.int32)\n",
    "                             )\n",
    "print(lending_co_lt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[b'LoanID' b'StringID' b'Product' ... b'Location' b'Region'\n",
      "  b'TotalPrice']\n",
      " [b'1' b'id_1' b'Product B' ... b'Location 2' b'Region 2' b'16600.0']\n",
      " [b'2' b'id_2' b'Product B' ... b'Location 3' b'' b'16600.0']\n",
      " ...\n",
      " [b'1041' b'id_1041' b'Product B' ... b'Location 23' b'Region 4'\n",
      "  b'16600.0']\n",
      " [b'1042' b'id_1042' b'Product C' ... b'Location 52' b'Region 6'\n",
      "  b'15600.0']\n",
      " [b'1043' b'id_1043' b'Product B' ... b'Location 142' b'Region 6'\n",
      "  b'16600.0']]\n"
     ]
    }
   ],
   "source": [
    "# way 4: rendered as object\n",
    "# similar output to string, but 'b' indicates that we are concerned with objects\n",
    "# necessary for backward compatibility with older versions of np\n",
    "\n",
    "lending_co_lt = np.genfromtxt(\"lending-co-LT.csv\", \n",
    "                              delimiter = ',',\n",
    "                              #dtype = np.int32\n",
    "                              #dtype = np.float16\n",
    "                              #dtype = np.str_\n",
    "                              dtype = object\n",
    "                              #dtype = (np.int32, np.str_, np.str_, np.str_, np.str_, np.str_, np.int32)\n",
    "                             )\n",
    "print(lending_co_lt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(  -1, '', '', '', '', '',    -1) (   1, '', '', '', '', '', 16600)\n",
      " (   2, '', '', '', '', '', 16600) ... (1041, '', '', '', '', '', 16600)\n",
      " (1042, '', '', '', '', '', 15600) (1043, '', '', '', '', '', 16600)]\n"
     ]
    }
   ],
   "source": [
    "# way 5: determine dtype per column\n",
    "\n",
    "lending_co_lt = np.genfromtxt(\"lending-co-LT.csv\", \n",
    "                              delimiter = ',',\n",
    "                              #dtype = np.int32\n",
    "                              #dtype = np.float16\n",
    "                              #dtype = np.str_\n",
    "                              #dtype = object\n",
    "                              dtype = (np.int32, np.str_, np.str_, np.str_, np.str_, np.str_, np.int32)\n",
    "                             )\n",
    "print(lending_co_lt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
