{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing with NumPy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### 1. Dealing with Missing Values\n",
    "- **a. Finding Missing Values**\n",
    "  - Method 1: Using `np.loadtxt()`\n",
    "  - Method 2: Using `np.isnan()`\n",
    "\n",
    "- **b. Temporarily Filling Missing Values**\n",
    "  - Method 1: Fill with `0`\n",
    "  - Method 2: Fill with `np.nanmax() + 1`\n",
    "\n",
    "- **c. Substituting Missing Values**\n",
    "  - Replace with `np.nanmean()` using `np.where()`\n",
    "\n",
    "#### 2. Reshaping Arrays\n",
    "- Using `np.reshape()`\n",
    "- Using `np.transpose()`\n",
    "\n",
    "#### 3. Removing Values\n",
    "- Using `np.delete()`\n",
    "\n",
    "#### 4. Sorting Data\n",
    "- Using `np.sort()`\n",
    "- Sorting with axis and slicing\n",
    "\n",
    "#### 5. Argument Functions: Finding Indices\n",
    "- `np.argsort()`\n",
    "- `np.argwhere()`\n",
    "\n",
    "#### 6. Shuffling Data\n",
    "- Shuffling with `np.random.shuffle()`\n",
    "- Shuffling with Random Generators\n",
    "\n",
    "#### 7. Type Casting\n",
    "- Changing data types using `astype()`\n",
    "\n",
    "#### 8. Stripping Data\n",
    "- Using `np.char.strip()` for text data\n",
    "\n",
    "#### 9. Stacking Arrays\n",
    "- Using `np.stack()`\n",
    "- Using `np.vstack()`\n",
    "- Using `np.hstack()`\n",
    "- Using `np.dstack()`\n",
    "\n",
    "#### 10. Concatenating Arrays\n",
    "- Concatenate arrays along different axes\n",
    "\n",
    "#### 11. Unique Values\n",
    "- Using `np.unique()` to find unique elements\n",
    "- Options: `return_counts`, `return_index`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Dealing with Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) Finding missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Method 1: Use loadtxt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a) we can use loadtxt() to check for missing values:\n",
    "# if np.loadtxt() compiles the dataset consists of only numeric values and has no missing data\n",
    "\n",
    "lending_co_data_numeric = np.loadtxt(\"Lending-company-Numeric.csv\", delimiter = ',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Method 2: Use isnan()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False, False, False, False, False, False],\n",
       "       [False, False, False, False, False, False],\n",
       "       [False, False, False, False, False, False],\n",
       "       ...,\n",
       "       [False, False, False, False, False, False],\n",
       "       [False, False, False, False, False, False],\n",
       "       [False, False, False, False, False, False]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# b) isnan() determines whether data is missing data for the individual elements in an array \n",
    "# (True -> Missing, False -> Not missing)\n",
    "\n",
    "np.isnan(lending_co_data_numeric)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# because False and True also have a numeric value: True = 1 and False = 0\n",
    "# we can also easily check the total number of missing values in dataset by adding .sum()\n",
    "\n",
    "np.isnan(lending_co_data_numeric).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# introduce other dataset that does have missing values\n",
    "\n",
    "lending_co_data_numeric_NAN = np.genfromtxt(\"Lending-company-Numeric-NAN.csv\", delimiter = ';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False, False, False, False, False, False],\n",
       "       [False, False, False, False, False, False],\n",
       "       [False, False, False, False, False, False],\n",
       "       ...,\n",
       "       [ True, False, False, False, False, False],\n",
       "       [False, False, False, False, False, False],\n",
       "       [False, False, False, False, False, False]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isnan(lending_co_data_numeric_NAN) # we see a True-value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(260)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isnan(lending_co_data_numeric_NAN).sum() # 260 missing values in total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1b) Temporarily fill in missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use genfromtxt() & 'filling_values' parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Method 1: set to = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filling_values substitutes every nan with the value we're passing (0 in this case)\n",
    "\n",
    "lending_co_data_numeric_NAN = np.genfromtxt(\"Lending-company-Numeric-NAN.csv\", \n",
    "                                            delimiter = ';',\n",
    "                                            filling_values = 0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# All the previously missing values are now 0s\n",
    "\n",
    "np.isnan(lending_co_data_numeric_NAN).sum()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Method 2: set to = np.panmax + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# but this is not ideal, because 0 could be part of dataset and obscures difference between real '0's and fill in '0's\n",
    "# better replace with values that certainly are not part of dataset; \n",
    "# later we can track them again and replace with an appropriate value\n",
    "# a common way to do this: take a value that is higher than any value in dataset\n",
    "\n",
    "\n",
    "# to do this: \n",
    "# 1) We need to reimport the dataset since all the missing values are filled up\n",
    "\n",
    "lending_co_data_numeric_NAN = np.genfromtxt(\"Lending-company-Numeric-NAN.csv\", \n",
    "                                            delimiter = ';') \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) We use nanmax(), since max() returns nan. \n",
    "\n",
    "temporary_fill = np.nanmax(lending_co_data_numeric_NAN).round(2) + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(64002.0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temporary_fill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "lending_co_data_numeric_NAN = np.genfromtxt(\"Lending-company-Numeric-NAN.csv\", \n",
    "                                            delimiter = ';',\n",
    "                                            filling_values = temporary_fill) \n",
    "\n",
    "# Filling up all the missing values with the temporary filler. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False, False, False, False, False, False],\n",
       "       [False, False, False, False, False, False],\n",
       "       [False, False, False, False, False, False],\n",
       "       ...,\n",
       "       [False, False, False, False, False, False],\n",
       "       [False, False, False, False, False, False],\n",
       "       [False, False, False, False, False, False]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isnan(lending_co_data_numeric_NAN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isnan(lending_co_data_numeric_NAN).sum() # we succesfully filled up missing values with temporary filler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1c) Substitute missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### set to = np.nanmean() with np.where()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2000.,    40.,   365.,  3121.,  4241., 13621.],\n",
       "       [ 2000.,    40.,   365.,  3061.,  4171., 15041.],\n",
       "       [ 1000.,    40.,   365.,  2160.,  3280., 15340.],\n",
       "       ...,\n",
       "       [   nan,    40.,   365.,  4201.,  5001., 16600.],\n",
       "       [ 1000.,    40.,   365.,  2080.,  3320., 15600.],\n",
       "       [ 2000.,    40.,   365.,  4601.,  4601., 16600.]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lending_co_data_numeric_NAN = np.genfromtxt(\"Lending-company-Numeric-NAN.csv\", delimiter = ';')\n",
    "lending_co_data_numeric_NAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "temporary_mean = np.nanmean(lending_co_data_numeric_NAN, axis = 0).round(2)\n",
    "\n",
    "## Storing the means of every column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(2250.25)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temporary_mean[0] # check mean of 1st column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we repeat what we did in 2.ii : temporarily fill in missing data with panmax +1\n",
    "\n",
    "temporary_fill = np.nanmax(lending_co_data_numeric_NAN).round(2) + 1\n",
    "\n",
    "lending_co_data_numeric_NAN = np.genfromtxt(\"Lending-company-Numeric-NAN.csv\",\n",
    "                                            delimiter = ';',\n",
    "                                            filling_values = temporary_fill)\n",
    "\n",
    "## Creating a unique filler and using it to take care of all the missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(64002.0)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temporary_fill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(4263.25)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(lending_co_data_numeric_NAN[:,0]).round(2) # Supposed mean (with new filled in values in place)\n",
    "# an enormous difference with mean without filled in values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Going through the first column and substituting any temporary fillers \n",
    "# (previously missing) with the mean for that column with np.where()\n",
    "# example for column 1 of dataset:\n",
    "\n",
    "lending_co_data_numeric_NAN[:,0] = np.where(lending_co_data_numeric_NAN[:,0] == temporary_fill,\n",
    "                                            temporary_mean[0], \n",
    "                                            lending_co_data_numeric_NAN[:,0])\n",
    "\n",
    "# np.where(condition, if met, if not met)\n",
    "# here: np.where current row = np.nanmax, \n",
    "# replace with np.nanmean() of column if the case, keep row as itself if not case \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(2250.25)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# new mean of first column now equals old mean without missing values\n",
    "# so this seems to work\n",
    "# this method wants to minimize the impact of missing values on calculations (although it is not always valid)\n",
    "\n",
    "np.mean(lending_co_data_numeric_NAN[:,0]).round(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As it seems to work, we apply this method to all columns in dataset \n",
    "\n",
    "for i in range(lending_co_data_numeric_NAN.shape[1]):        \n",
    "    lending_co_data_numeric_NAN[:,i] = np.where(lending_co_data_numeric_NAN[:,i] == temporary_fill, \n",
    "                                                temporary_mean[i], \n",
    "                                                lending_co_data_numeric_NAN[:,i])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can use this approach for other applications as well (e.g. remove all negative values and set them to 0)\n",
    "# or set them all to mode, or ... up to you as analyst\n",
    "\n",
    "for i in range(lending_co_data_numeric_NAN.shape[1]):        \n",
    "    lending_co_data_numeric_NAN[:,i] = np.where(lending_co_data_numeric_NAN[:, i] < 0,\n",
    "                                                0, \n",
    "                                                lending_co_data_numeric_NAN[:,i])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Reshaping\n",
    "\n",
    "    For certain computations manipulation of the shape of the arrays will be necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "\n",
    "lending_co_data_numeric = np.loadtxt(\"Lending-company-Numeric.csv\", delimiter = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2000.,    40.,   365.,  3121.,  4241., 13621.],\n",
       "       [ 2000.,    40.,   365.,  3061.,  4171., 15041.],\n",
       "       [ 1000.,    40.,   365.,  2160.,  3280., 15340.],\n",
       "       ...,\n",
       "       [ 2000.,    40.,   365.,  4201.,  5001., 16600.],\n",
       "       [ 1000.,    40.,   365.,  2080.,  3320., 15600.],\n",
       "       [ 2000.,    40.,   365.,  4601.,  4601., 16600.]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lending_co_data_numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1043, 6)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lending_co_data_numeric.shape # 1043 rows, 6 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2000.,    40.,   365., ...,   365.,  1581.,  3041.],\n",
       "       [12277.,  2000.,    40., ...,    50.,   365.,  5350.],\n",
       "       [ 6850., 15150.,  1000., ...,  2000.,    40.,   365.],\n",
       "       [ 3101.,  4351., 16600., ..., 16600.,  2000.,    40.],\n",
       "       [  365.,  3441.,  4661., ...,  8450., 22250.,  2000.],\n",
       "       [   40.,   365.,  3701., ...,  4601.,  4601., 16600.]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can reshape to array with 6 rows and 1043 columns: (1043,6)\n",
    "# However: this is not a flipped/transposed array!\n",
    "# Reshape has flattened array (one row after the other), \n",
    "# and has simply taken first 1043 values from that flattened array as the first row)\n",
    "# and so on.. \n",
    "# we can see that the first and last three values in original and reshaped array are indeed the same\n",
    "\n",
    "np.reshape(lending_co_data_numeric, (6,1043))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2000.,  2000.,  1000., ...,  2000.,  1000.,  2000.],\n",
       "       [   40.,    40.,    40., ...,    40.,    40.,    40.],\n",
       "       [  365.,   365.,   365., ...,   365.,   365.,   365.],\n",
       "       [ 3121.,  3061.,  2160., ...,  4201.,  2080.,  4601.],\n",
       "       [ 4241.,  4171.,  3280., ...,  5001.,  3320.,  4601.],\n",
       "       [13621., 15041., 15340., ..., 16600., 15600., 16600.]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If we want to transpose: use transpose() function\n",
    "\n",
    "np.transpose(lending_co_data_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2000.,    40.,   365.,  3121.,  4241., 13621.],\n",
       "       [ 2000.,    40.,   365.,  3061.,  4171., 15041.],\n",
       "       [ 1000.,    40.,   365.,  2160.,  3280., 15340.],\n",
       "       ...,\n",
       "       [ 2000.,    40.,   365.,  4201.,  5001., 16600.],\n",
       "       [ 1000.,    40.,   365.,  2080.,  3320., 15600.],\n",
       "       [ 2000.,    40.,   365.,  4601.,  4601., 16600.]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# even after transposing original array remains the same\n",
    "# so save to different variable if you want to re-use transposed array\n",
    "\n",
    "lending_co_data_numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 6258 into shape (3,500)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# If we want to give different shape\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlending_co_data_numeric\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m500\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/Udemy_NumPy/lib/python3.13/site-packages/numpy/_core/fromnumeric.py:328\u001b[0m, in \u001b[0;36mreshape\u001b[0;34m(a, shape, order, newshape, copy)\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    327\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapfunc(a, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreshape\u001b[39m\u001b[38;5;124m'\u001b[39m, shape, order\u001b[38;5;241m=\u001b[39morder, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[0;32m--> 328\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mreshape\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/Udemy_NumPy/lib/python3.13/site-packages/numpy/_core/fromnumeric.py:57\u001b[0m, in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 57\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbound\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;66;03m# A TypeError occurs if the object does have such a method in its\u001b[39;00m\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;66;03m# class, but its signature is not identical to that of NumPy's. This\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;66;03m# Call _wrapit from within the except clause to ensure a potential\u001b[39;00m\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;66;03m# exception has a traceback chain.\u001b[39;00m\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 6258 into shape (3,500)"
     ]
    }
   ],
   "source": [
    "# If we want to give different shape\n",
    "\n",
    "np.reshape(lending_co_data_numeric, (3,500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[[ 2000.,    40.,   365., ...,   365.,  1581.,  3041.],\n",
       "          [12277.,  2000.,    40., ...,    50.,   365.,  5350.],\n",
       "          [ 6850., 15150.,  1000., ...,  2000.,    40.,   365.]],\n",
       "\n",
       "         [[ 3101.,  4351., 16600., ..., 16600.,  2000.,    40.],\n",
       "          [  365.,  3441.,  4661., ...,  8450., 22250.,  2000.],\n",
       "          [   40.,   365.,  3701., ...,  4601.,  4601., 16600.]]]]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we cannot reshape array of size 6258 into shape (3,500)\n",
    "# because the number of elements in original and reshaped array should be equal\n",
    "# So we can choose whatever shape we wish \n",
    "# BUT the product of the dimensions must match the total number of elements in the array\n",
    "\n",
    "np.reshape(lending_co_data_numeric, (1,1,2,3,1043))\n",
    "\n",
    "# 1*1*2*3*1043 = 6258 elements, just like in original array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2000.,    40.,   365.,  3121.,  4241., 13621.],\n",
       "       [ 2000.,    40.,   365.,  3061.,  4171., 15041.],\n",
       "       [ 1000.,    40.,   365.,  2160.,  3280., 15340.],\n",
       "       ...,\n",
       "       [ 2000.,    40.,   365.,  4201.,  5001., 16600.],\n",
       "       [ 1000.,    40.,   365.,  2080.,  3320., 15600.],\n",
       "       [ 2000.,    40.,   365.,  4601.,  4601., 16600.]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reshaping does not alter original array\n",
    "# original array stays the same\n",
    "\n",
    "lending_co_data_numeric\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2000.,    40.,   365., ...,   365.,  1581.,  3041.],\n",
       "       [12277.,  2000.,    40., ...,    50.,   365.,  5350.],\n",
       "       [ 6850., 15150.,  1000., ...,  2000.,    40.,   365.],\n",
       "       [ 3101.,  4351., 16600., ..., 16600.,  2000.,    40.],\n",
       "       [  365.,  3441.,  4661., ...,  8450., 22250.,  2000.],\n",
       "       [   40.,   365.,  3701., ...,  4601.,  4601., 16600.]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# therefore, store reshaped array if you want te use multiple times\n",
    "\n",
    "lending_co_data_numeric_2 = np.reshape(lending_co_data_numeric, (6,1043))\n",
    "lending_co_data_numeric_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2000.,    40.,   365., ...,   365.,  1581.,  3041.],\n",
       "       [12277.,  2000.,    40., ...,    50.,   365.,  5350.],\n",
       "       [ 6850., 15150.,  1000., ...,  2000.,    40.,   365.],\n",
       "       [ 3101.,  4351., 16600., ..., 16600.,  2000.,    40.],\n",
       "       [  365.,  3441.,  4661., ...,  8450., 22250.,  2000.],\n",
       "       [   40.,   365.,  3701., ...,  4601.,  4601., 16600.]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Equivalent method\n",
    "\n",
    "lending_co_data_numeric.reshape(6,1043)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2000.,    40.,   365.,  3121.,  4241., 13621.],\n",
       "       [ 2000.,    40.,   365.,  3061.,  4171., 15041.],\n",
       "       [ 1000.,    40.,   365.,  2160.,  3280., 15340.],\n",
       "       ...,\n",
       "       [ 2000.,    40.,   365.,  4201.,  5001., 16600.],\n",
       "       [ 1000.,    40.,   365.,  2080.,  3320., 15600.],\n",
       "       [ 2000.,    40.,   365.,  4601.,  4601., 16600.]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lending_co_data_numeric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Removing Values\n",
    "\n",
    "    Use np.delete() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dataset\n",
    "\n",
    "lending_co_data_numeric = np.loadtxt(\"Lending-company-Numeric.csv\", delimiter = ',') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2000.,    40.,   365.,  3121.,  4241., 13621.],\n",
       "       [ 2000.,    40.,   365.,  3061.,  4171., 15041.],\n",
       "       [ 1000.,    40.,   365.,  2160.,  3280., 15340.],\n",
       "       ...,\n",
       "       [ 2000.,    40.,   365.,  4201.,  5001., 16600.],\n",
       "       [ 1000.,    40.,   365.,  2080.,  3320., 15600.],\n",
       "       [ 2000.,    40.,   365.,  4601.,  4601., 16600.]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lending_co_data_numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6258"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lending_co_data_numeric.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6257,)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removes first single value of the flattened array\n",
    "\n",
    "np.delete(lending_co_data_numeric, 0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2000.,    40.,   365.,  3121.,  4241., 13621.],\n",
       "       [ 2000.,    40.,   365.,  3061.,  4171., 15041.],\n",
       "       [ 1000.,    40.,   365.,  2160.,  3280., 15340.],\n",
       "       ...,\n",
       "       [ 2000.,    40.,   365.,  4201.,  5001., 16600.],\n",
       "       [ 1000.,    40.,   365.,  2080.,  3320., 15600.],\n",
       "       [ 2000.,    40.,   365.,  4601.,  4601., 16600.]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# as with transpose() and reshape() original array remains same\n",
    "\n",
    "lending_co_data_numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   40.,  3121., 13621.],\n",
       "       [   40.,  3061., 15041.],\n",
       "       [   40.,  2160., 15340.],\n",
       "       ...,\n",
       "       [   40.,  4201., 16600.],\n",
       "       [   40.,  2080., 15600.],\n",
       "       [   40.,  4601., 16600.]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# By setting an axis, we can simultaneously delete entire rows or columns\n",
    "\n",
    "np.delete(lending_co_data_numeric, [0,2,4] , axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   40.,  3061., 15041.],\n",
       "       [   40.,  3041., 15321.],\n",
       "       [   50.,  3470., 13720.],\n",
       "       ...,\n",
       "       [   40.,  4240., 16600.],\n",
       "       [   40.,  4201., 16600.],\n",
       "       [   40.,  2080., 15600.]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can simultaneously delete rows AND columns\n",
    "# put np.delete() for axis 1 inside np.delete() for axis 0:\n",
    "\n",
    "np.delete(np.delete(lending_co_data_numeric, [0,2,4] , axis = 1), [0,2,-1] , axis = 0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Sorting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2000.,    40.,   365.,  3121.,  4241., 13621.],\n",
       "       [ 2000.,    40.,   365.,  3061.,  4171., 15041.],\n",
       "       [ 1000.,    40.,   365.,  2160.,  3280., 15340.],\n",
       "       ...,\n",
       "       [ 2000.,    40.,   365.,  4201.,  5001., 16600.],\n",
       "       [ 1000.,    40.,   365.,  2080.,  3320., 15600.],\n",
       "       [ 2000.,    40.,   365.,  4601.,  4601., 16600.]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load dataset\n",
    "\n",
    "lending_co_data_numeric = np.loadtxt(\"Lending-company-Numeric.csv\", delimiter = ',') \n",
    "lending_co_data_numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1043, 6)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lending_co_data_numeric.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   40.,   365.,  2000.,  3121.,  4241., 13621.],\n",
       "       [   40.,   365.,  2000.,  3061.,  4171., 15041.],\n",
       "       [   40.,   365.,  1000.,  2160.,  3280., 15340.],\n",
       "       ...,\n",
       "       [   40.,   365.,  2000.,  4201.,  5001., 16600.],\n",
       "       [   40.,   365.,  1000.,  2080.,  3320., 15600.],\n",
       "       [   40.,   365.,  2000.,  4601.,  4601., 16600.]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# by default sorting occurs by axis = dimension - 1\n",
    "# here we have a 2-D array so sorting happens along 2-1= 1, axis 1\n",
    "# rearrange columns : each row is sorted from low to high\n",
    "\n",
    "np.sort(lending_co_data_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1043, 6)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shape remains the same: only values are put in different place\n",
    "\n",
    "np.sort(lending_co_data_numeric).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2870., -2870., -2550., ..., 54625., 54625., 64001.])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if we want to work with a flattened array: set axis to None\n",
    "\n",
    "np.sort(lending_co_data_numeric, axis = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-13621.,  -4241.,  -3121.,  -2000.,   -365.,    -40.],\n",
       "       [-15041.,  -4171.,  -3061.,  -2000.,   -365.,    -40.],\n",
       "       [-15340.,  -3280.,  -2160.,  -1000.,   -365.,    -40.],\n",
       "       ...,\n",
       "       [-16600.,  -5001.,  -4201.,  -2000.,   -365.,    -40.],\n",
       "       [-15600.,  -3320.,  -2080.,  -1000.,   -365.,    -40.],\n",
       "       [-16600.,  -4601.,  -4601.,  -2000.,   -365.,    -40.]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adding 1 minus sign changes sign of every element: large values become small, & vice versa\n",
    "# however: this array remains sorted in ascending order\n",
    "\n",
    "np.sort(-lending_co_data_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[13621.,  4241.,  3121.,  2000.,   365.,    40.],\n",
       "       [15041.,  4171.,  3061.,  2000.,   365.,    40.],\n",
       "       [15340.,  3280.,  2160.,  1000.,   365.,    40.],\n",
       "       ...,\n",
       "       [16600.,  5001.,  4201.,  2000.,   365.,    40.],\n",
       "       [15600.,  3320.,  2080.,  1000.,   365.,    40.],\n",
       "       [16600.,  4601.,  4601.,  2000.,   365.,    40.]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adding two minus signs sorts the array in descending order\n",
    "\n",
    "-np.sort(-lending_co_data_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2000.,    40.,   365.,  3121.,  4241., 13621.],\n",
       "       [ 2000.,    40.,   365.,  3061.,  4171., 15041.],\n",
       "       [ 1000.,    40.,   365.,  2160.,  3280., 15340.],\n",
       "       ...,\n",
       "       [ 2000.,    40.,   365.,  4201.,  5001., 16600.],\n",
       "       [ 1000.,    40.,   365.,  2080.,  3320., 15600.],\n",
       "       [ 2000.,    40.,   365.,  4601.,  4601., 16600.]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# as with other functions reshape(), transpose(), delete() the original array remains same\n",
    "\n",
    "lending_co_data_numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.0000e+03,  3.5000e+01,  3.6500e+02, -2.8700e+03, -2.8700e+03,\n",
       "        -3.5000e+02],\n",
       "       [ 1.0000e+03,  3.5000e+01,  3.6500e+02, -2.5500e+03, -2.1000e+03,\n",
       "         1.5000e+02],\n",
       "       [ 1.0000e+03,  3.5000e+01,  3.6500e+02, -2.4500e+03, -2.0000e+03,\n",
       "         1.1000e+03],\n",
       "       ...,\n",
       "       [ 9.0000e+03,  1.2500e+02,  3.6500e+02,  1.6751e+04,  1.8751e+04,\n",
       "         5.4625e+04],\n",
       "       [ 9.0000e+03,  1.6500e+02,  3.6500e+02,  1.7650e+04,  2.0001e+04,\n",
       "         5.4625e+04],\n",
       "       [ 9.0000e+03,  1.6500e+02,  3.6500e+02,  1.9001e+04,  2.2001e+04,\n",
       "         6.4001e+04]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The equivalent method, however, stores the values in place\n",
    "# here original array is altered\n",
    "\n",
    "lending_co_data_numeric.sort(axis = 0)\n",
    "lending_co_data_numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1000.,    35.,   365., -2870., -2870.,  -350.],\n",
       "       [ 1000.,    35.,   365., -2550., -2100.,   150.],\n",
       "       [ 1000.,    35.,   365., -2450., -2000.,  1100.],\n",
       "       ...,\n",
       "       [ 9000.,   125.,   365., 16751., 18751., 54625.],\n",
       "       [ 9000.,   165.,   365., 17650., 20001., 54625.],\n",
       "       [ 9000.,   165.,   365., 19001., 22001., 64001.]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.set_printoptions(suppress=True) # simplifies scientific notation\n",
    "lending_co_data_numeric # & indeed, are array now has been altered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2870., -2550., -2450., ..., 16751., 17650., 19001.])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can also sort individual columns and rows by indexing\n",
    "\n",
    "np.sort(lending_co_data_numeric[:,3]) # select only 3th column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Argument Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Argument functions return information on the coordinates of elements within coordinate space,\n",
    "i.e. information on indices of elements within rows and columns of dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### np.argsort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2000.,    40.,   365.,  3121.,  4241., 13621.],\n",
       "       [ 2000.,    40.,   365.,  3061.,  4171., 15041.],\n",
       "       [ 1000.,    40.,   365.,  2160.,  3280., 15340.],\n",
       "       ...,\n",
       "       [ 2000.,    40.,   365.,  4201.,  5001., 16600.],\n",
       "       [ 1000.,    40.,   365.,  2080.,  3320., 15600.],\n",
       "       [ 2000.,    40.,   365.,  4601.,  4601., 16600.]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import dataset\n",
    "\n",
    "lending_co_data_numeric = np.loadtxt(\"Lending-company-Numeric.csv\", delimiter = ',') \n",
    "lending_co_data_numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 0, 3, 4, 5],\n",
       "       [1, 2, 0, 3, 4, 5],\n",
       "       [1, 2, 0, 3, 4, 5],\n",
       "       ...,\n",
       "       [1, 2, 0, 3, 4, 5],\n",
       "       [1, 2, 0, 3, 4, 5],\n",
       "       [1, 2, 0, 3, 4, 5]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Returns the order of indices of sorted values of array\n",
    "\n",
    "np.argsort(lending_co_data_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 537,  443,    0,   32,   32,  482],\n",
       "       [ 639,  327,  687,  166,  166,  493],\n",
       "       [ 849,  432,  688,   85,   85,  166],\n",
       "       ...,\n",
       "       [  27,  326,  355,  568, 1019,  568],\n",
       "       [ 277,   27,  357,  718, 1033,  534],\n",
       "       [ 420,  408, 1042,  912,  912,   27]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can also sort by axis\n",
    "\n",
    "np.argsort(lending_co_data_numeric, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(-350.0)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# in column 5 value at row 482 would be the lowest value\n",
    "# the value of this element is -350\n",
    "\n",
    "lending_co_data_numeric[482,5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1000.,    35.,   365., -2870., -2870.,  -350.],\n",
       "       [ 1000.,    35.,   365., -2550., -2100.,   150.],\n",
       "       [ 1000.,    35.,   365., -2450., -2000.,  1100.],\n",
       "       ...,\n",
       "       [ 9000.,   125.,   365., 16751., 18751., 54625.],\n",
       "       [ 9000.,   165.,   365., 17650., 20001., 54625.],\n",
       "       [ 9000.,   165.,   365., 19001., 22001., 64001.]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can check whether this smallest element by sorting array by rows:\n",
    "# - 350 is indeed lowest value in column 5\n",
    "\n",
    "np.sort(lending_co_data_numeric, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([537, 639, 849, ...,  27, 277, 420])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can sort an individual column\n",
    "\n",
    "np.argsort(lending_co_data_numeric[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1000.,    40.,   365.,  2200.,  3400., 15600.],\n",
       "       [ 1000.,    40.,   365.,  2200.,  3800., 15600.],\n",
       "       [ 1000.,    40.,   365.,  2000.,  3950., 15600.],\n",
       "       ...,\n",
       "       [ 9000.,   165.,   365., 14501., 16846., 64001.],\n",
       "       [ 9000.,   125.,   365., 12001., 15751., 38626.],\n",
       "       [ 9000.,   125.,   365., 12251., 14251., 25626.]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can now sort whole the array by this first column\n",
    "\n",
    "lending_co_data_numeric = lending_co_data_numeric[np.argsort(lending_co_data_numeric[:,0])]\n",
    "lending_co_data_numeric\n",
    "\n",
    "# and we see that values in first column are sorted, but not the values in the other columns,\n",
    "# so correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,   22,    0,  199,  199,  172],\n",
       "       [ 155,   62,  687,   53,   53,  160],\n",
       "       [ 156,   38,  688,  169,  169,   53],\n",
       "       ...,\n",
       "       [1022, 1042,  355, 1024, 1037, 1023],\n",
       "       [1031, 1039,  357,  941, 1029, 1024],\n",
       "       [1042, 1040, 1042, 1027, 1027, 1040]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Contrary to other methods, this method doesn't sort in place\n",
    "\n",
    "lending_co_data_numeric.argsort(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1000.,    40.,   365.,  2200.,  3400., 15600.],\n",
       "       [ 1000.,    40.,   365.,  2200.,  3800., 15600.],\n",
       "       [ 1000.,    40.,   365.,  2000.,  3950., 15600.],\n",
       "       ...,\n",
       "       [ 9000.,   165.,   365., 14501., 16846., 64001.],\n",
       "       [ 9000.,   125.,   365., 12001., 15751., 38626.],\n",
       "       [ 9000.,   125.,   365., 12251., 14251., 25626.]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lending_co_data_numeric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### np.argwhere()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2000.,    40.,   365.,  3121.,  4241., 13621.],\n",
       "       [ 2000.,    40.,   365.,  3061.,  4171., 15041.],\n",
       "       [ 1000.,    40.,   365.,  2160.,  3280., 15340.],\n",
       "       ...,\n",
       "       [ 2000.,    40.,   365.,  4201.,  5001., 16600.],\n",
       "       [ 1000.,    40.,   365.,  2080.,  3320., 15600.],\n",
       "       [ 2000.,    40.,   365.,  4601.,  4601., 16600.]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load dataset\n",
    "\n",
    "lending_co_data_numeric = np.loadtxt(\"Lending-company-Numeric.csv\", delimiter = ',') \n",
    "lending_co_data_numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0],\n",
       "       [   0,    1],\n",
       "       [   0,    2],\n",
       "       ...,\n",
       "       [1042,    3],\n",
       "       [1042,    4],\n",
       "       [1042,    5]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checks whether individual elements satisfy a condition\n",
    "# outputs coordinates of each element that satisfies condition\n",
    "# with row index in 1st & columnn index in 2nd column\n",
    "\n",
    "np.argwhere(lending_co_data_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[116,   4],\n",
       "       [430,   3]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# But: we did not specify any condition?\n",
    "# default condition = return values different from 0\n",
    "\n",
    "# if we reverse that condition, we get:\n",
    "\n",
    "np.argwhere(lending_co_data_numeric == False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1000.    50.   365. -1450.     0. 13850.]\n",
      "[1000.   50.  365.    0.  550. 5650.]\n"
     ]
    }
   ],
   "source": [
    "# this result suggests there are only 2 rows in dataset with 0 - values\n",
    "# to check whether this is correct, we can print the values of both rows\n",
    "\n",
    "print(lending_co_data_numeric[116])\n",
    "print(lending_co_data_numeric[430])\n",
    "\n",
    "# and indeed, they hold zero values in the specified columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0],\n",
       "       [   0,    1],\n",
       "       [   1,    0],\n",
       "       ...,\n",
       "       [1042,    0],\n",
       "       [1042,    1],\n",
       "       [1042,    5]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The condition can be more complex: >, <, even, uneven\n",
    "\n",
    "np.argwhere(lending_co_data_numeric %2 == 0)\n",
    "\n",
    "# we can use function to separate elements that interest us\n",
    "# and only examine those\n",
    "\n",
    "\n",
    "# Similar to 'filtering' on the basis of conditional slicing\n",
    "# difference: \n",
    "# slicing gives us actual values of elements \n",
    "# <--> np.argwhere() gives us coordinates of elements\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if we want to know where to find certain values in dataset\n",
    "# we can use this function\n",
    "# for example: find missing values\n",
    "\n",
    "np.isnan(lending_co_data_numeric).sum()\n",
    "\n",
    "# in the current dataset no missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2000.,    40.,   365.,  3121.,  4241., 13621.],\n",
       "       [ 2000.,    40.,   365.,  3061.,  4171., 15041.],\n",
       "       [ 1000.,    40.,   365.,  2160.,  3280., 15340.],\n",
       "       ...,\n",
       "       [   nan,    40.,   365.,  4201.,  5001., 16600.],\n",
       "       [ 1000.,    40.,   365.,  2080.,  3320., 15600.],\n",
       "       [ 2000.,    40.,   365.,  4601.,  4601., 16600.]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# so we load another dataset with missing values, so we can illustrate this\n",
    "\n",
    "lending_co_data_numeric_NAN = np.genfromtxt(\"Lending-company-Numeric-NAN.csv\", delimiter = ';') \n",
    "lending_co_data_numeric_NAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False, False, False, False, False, False],\n",
       "       [False, False, False, False, False, False],\n",
       "       [False, False, False, False, False, False],\n",
       "       ...,\n",
       "       [ True, False, False, False, False, False],\n",
       "       [False, False, False, False, False, False],\n",
       "       [False, False, False, False, False, False]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# np.isnan returns boolean for every element; True = 1; False = 0\n",
    "\n",
    "np.isnan(lending_co_data_numeric_NAN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  11,    3],\n",
       "       [  15,    3],\n",
       "       [  27,    3],\n",
       "       [  58,    3],\n",
       "       [  60,    4],\n",
       "       [  85,    4],\n",
       "       [ 117,    5],\n",
       "       [ 152,    1],\n",
       "       [ 152,    2],\n",
       "       [ 152,    4],\n",
       "       [ 172,    1],\n",
       "       [ 175,    1],\n",
       "       [ 175,    2],\n",
       "       [ 176,    3],\n",
       "       [ 177,    4],\n",
       "       [ 178,    5],\n",
       "       [ 211,    3],\n",
       "       [ 229,    0],\n",
       "       [ 230,    1],\n",
       "       [ 237,    1],\n",
       "       [ 247,    3],\n",
       "       [ 251,    5],\n",
       "       [ 252,    4],\n",
       "       [ 258,    1],\n",
       "       [ 260,    3],\n",
       "       [ 262,    4],\n",
       "       [ 271,    5],\n",
       "       [ 272,    4],\n",
       "       [ 284,    2],\n",
       "       [ 284,    3],\n",
       "       [ 297,    1],\n",
       "       [ 297,    2],\n",
       "       [ 300,    3],\n",
       "       [ 315,    3],\n",
       "       [ 315,    5],\n",
       "       [ 327,    4],\n",
       "       [ 336,    4],\n",
       "       [ 343,    0],\n",
       "       [ 344,    2],\n",
       "       [ 346,    2],\n",
       "       [ 363,    3],\n",
       "       [ 375,    3],\n",
       "       [ 377,    2],\n",
       "       [ 398,    5],\n",
       "       [ 416,    4],\n",
       "       [ 428,    0],\n",
       "       [ 432,    1],\n",
       "       [ 433,    3],\n",
       "       [ 434,    2],\n",
       "       [ 440,    3],\n",
       "       [ 441,    1],\n",
       "       [ 446,    2],\n",
       "       [ 455,    1],\n",
       "       [ 456,    2],\n",
       "       [ 458,    2],\n",
       "       [ 461,    3],\n",
       "       [ 467,    4],\n",
       "       [ 468,    0],\n",
       "       [ 469,    3],\n",
       "       [ 470,    0],\n",
       "       [ 481,    1],\n",
       "       [ 482,    3],\n",
       "       [ 484,    4],\n",
       "       [ 489,    0],\n",
       "       [ 493,    5],\n",
       "       [ 499,    0],\n",
       "       [ 504,    3],\n",
       "       [ 506,    1],\n",
       "       [ 517,    4],\n",
       "       [ 518,    0],\n",
       "       [ 521,    2],\n",
       "       [ 530,    5],\n",
       "       [ 532,    3],\n",
       "       [ 534,    5],\n",
       "       [ 547,    3],\n",
       "       [ 549,    5],\n",
       "       [ 553,    5],\n",
       "       [ 554,    5],\n",
       "       [ 559,    3],\n",
       "       [ 566,    0],\n",
       "       [ 566,    1],\n",
       "       [ 566,    2],\n",
       "       [ 567,    0],\n",
       "       [ 567,    1],\n",
       "       [ 567,    2],\n",
       "       [ 581,    1],\n",
       "       [ 581,    2],\n",
       "       [ 582,    1],\n",
       "       [ 582,    2],\n",
       "       [ 583,    1],\n",
       "       [ 583,    2],\n",
       "       [ 593,    3],\n",
       "       [ 594,    3],\n",
       "       [ 595,    3],\n",
       "       [ 596,    3],\n",
       "       [ 609,    4],\n",
       "       [ 609,    5],\n",
       "       [ 610,    4],\n",
       "       [ 610,    5],\n",
       "       [ 611,    4],\n",
       "       [ 611,    5],\n",
       "       [ 612,    4],\n",
       "       [ 612,    5],\n",
       "       [ 623,    2],\n",
       "       [ 623,    3],\n",
       "       [ 624,    2],\n",
       "       [ 624,    3],\n",
       "       [ 625,    2],\n",
       "       [ 625,    3],\n",
       "       [ 626,    2],\n",
       "       [ 626,    3],\n",
       "       [ 627,    2],\n",
       "       [ 627,    3],\n",
       "       [ 636,    0],\n",
       "       [ 637,    0],\n",
       "       [ 637,    4],\n",
       "       [ 637,    5],\n",
       "       [ 638,    0],\n",
       "       [ 638,    4],\n",
       "       [ 638,    5],\n",
       "       [ 639,    4],\n",
       "       [ 639,    5],\n",
       "       [ 640,    4],\n",
       "       [ 640,    5],\n",
       "       [ 641,    4],\n",
       "       [ 641,    5],\n",
       "       [ 653,    1],\n",
       "       [ 653,    2],\n",
       "       [ 653,    3],\n",
       "       [ 653,    4],\n",
       "       [ 654,    1],\n",
       "       [ 654,    2],\n",
       "       [ 654,    3],\n",
       "       [ 654,    4],\n",
       "       [ 655,    1],\n",
       "       [ 655,    2],\n",
       "       [ 655,    3],\n",
       "       [ 655,    4],\n",
       "       [ 685,    2],\n",
       "       [ 686,    0],\n",
       "       [ 701,    4],\n",
       "       [ 704,    2],\n",
       "       [ 724,    1],\n",
       "       [ 724,    2],\n",
       "       [ 730,    1],\n",
       "       [ 730,    2],\n",
       "       [ 730,    3],\n",
       "       [ 731,    1],\n",
       "       [ 731,    2],\n",
       "       [ 731,    3],\n",
       "       [ 732,    1],\n",
       "       [ 732,    2],\n",
       "       [ 732,    3],\n",
       "       [ 733,    1],\n",
       "       [ 733,    2],\n",
       "       [ 733,    3],\n",
       "       [ 742,    4],\n",
       "       [ 747,    3],\n",
       "       [ 755,    1],\n",
       "       [ 758,    1],\n",
       "       [ 760,    1],\n",
       "       [ 764,    0],\n",
       "       [ 764,    1],\n",
       "       [ 764,    2],\n",
       "       [ 764,    3],\n",
       "       [ 764,    4],\n",
       "       [ 764,    5],\n",
       "       [ 765,    3],\n",
       "       [ 775,    1],\n",
       "       [ 775,    2],\n",
       "       [ 775,    3],\n",
       "       [ 776,    1],\n",
       "       [ 776,    2],\n",
       "       [ 776,    3],\n",
       "       [ 777,    1],\n",
       "       [ 777,    2],\n",
       "       [ 777,    3],\n",
       "       [ 778,    1],\n",
       "       [ 778,    2],\n",
       "       [ 778,    3],\n",
       "       [ 787,    4],\n",
       "       [ 788,    1],\n",
       "       [ 790,    2],\n",
       "       [ 794,    3],\n",
       "       [ 795,    5],\n",
       "       [ 796,    1],\n",
       "       [ 796,    4],\n",
       "       [ 800,    0],\n",
       "       [ 801,    1],\n",
       "       [ 802,    1],\n",
       "       [ 803,    2],\n",
       "       [ 805,    0],\n",
       "       [ 809,    0],\n",
       "       [ 810,    0],\n",
       "       [ 811,    0],\n",
       "       [ 812,    1],\n",
       "       [ 820,    0],\n",
       "       [ 820,    3],\n",
       "       [ 820,    4],\n",
       "       [ 822,    2],\n",
       "       [ 823,    2],\n",
       "       [ 825,    0],\n",
       "       [ 830,    1],\n",
       "       [ 830,    2],\n",
       "       [ 836,    3],\n",
       "       [ 837,    3],\n",
       "       [ 838,    3],\n",
       "       [ 839,    4],\n",
       "       [ 843,    2],\n",
       "       [ 856,    0],\n",
       "       [ 856,    1],\n",
       "       [ 856,    3],\n",
       "       [ 856,    4],\n",
       "       [ 856,    5],\n",
       "       [ 857,    0],\n",
       "       [ 858,    1],\n",
       "       [ 870,    0],\n",
       "       [ 870,    2],\n",
       "       [ 870,    3],\n",
       "       [ 872,    0],\n",
       "       [ 873,    0],\n",
       "       [ 874,    1],\n",
       "       [ 890,    1],\n",
       "       [ 890,    2],\n",
       "       [ 890,    3],\n",
       "       [ 909,    1],\n",
       "       [ 910,    0],\n",
       "       [ 912,    0],\n",
       "       [ 912,    2],\n",
       "       [ 912,    3],\n",
       "       [ 912,    4],\n",
       "       [ 928,    1],\n",
       "       [ 928,    2],\n",
       "       [ 928,    3],\n",
       "       [ 929,    1],\n",
       "       [ 929,    2],\n",
       "       [ 929,    3],\n",
       "       [ 930,    3],\n",
       "       [ 958,    2],\n",
       "       [ 959,    3],\n",
       "       [ 960,    3],\n",
       "       [1024,    0],\n",
       "       [1024,    2],\n",
       "       [1026,    2],\n",
       "       [1026,    4],\n",
       "       [1028,    0],\n",
       "       [1028,    3],\n",
       "       [1028,    4],\n",
       "       [1029,    0],\n",
       "       [1030,    1],\n",
       "       [1030,    5],\n",
       "       [1032,    0],\n",
       "       [1032,    5],\n",
       "       [1034,    3],\n",
       "       [1035,    4],\n",
       "       [1036,    2],\n",
       "       [1037,    1],\n",
       "       [1038,    4],\n",
       "       [1039,    3],\n",
       "       [1040,    0]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If we now take this as the condition/the argument\n",
    "# for our np.where function, we get indices of all missing values\n",
    "\n",
    "np.argwhere(np.isnan(lending_co_data_numeric_NAN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2000.,    nan,    nan,  1851.,  3051., 13561.])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking the values on the indices confirms there are missing values\n",
    "\n",
    "lending_co_data_numeric_NAN[175]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and by going through the coordinates of all the mising values of the array, \n",
    "# we can easily fill them up:\n",
    "\n",
    "for array_index in np.argwhere(np.isnan(lending_co_data_numeric_NAN)):\n",
    "    lending_co_data_numeric_NAN[array_index[0], array_index[1]] = 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2000.,     0.,     0.,  1851.,  3051., 13561.])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# and indeed: the nan on indices 1 and 2 are replaced with '0'\n",
    "\n",
    "lending_co_data_numeric_NAN[175]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# and there are no missing values left in dataset\n",
    "\n",
    "np.isnan(lending_co_data_numeric_NAN).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Shuffling Data\n",
    "\n",
    "Randomly rearrange dataset so that random sample would be representative of entire dataset. Rows in dataset as cards in deck of cards that get shufled. Entire row is moved up or down in dataset, but contents of each row remains unchanged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2000.,    40.,   365.,  3121.,  4241., 13621.],\n",
       "       [ 2000.,    40.,   365.,  3061.,  4171., 15041.],\n",
       "       [ 1000.,    40.,   365.,  2160.,  3280., 15340.],\n",
       "       [ 2000.,    40.,   365.,  3041.,  4241., 15321.],\n",
       "       [ 2000.,    50.,   365.,  3470.,  4820., 13720.],\n",
       "       [ 2000.,    40.,   365.,  3201.,  4141., 14141.],\n",
       "       [ 2000.,    50.,   365.,  1851.,  3251., 17701.],\n",
       "       [ 2000.,    40.,   365.,  3971.,  4131., 15351.]])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to illustrate in first instance, we load only first 8 rows of dataset\n",
    "\n",
    "lending_co_data_numeric = np.loadtxt(\"Lending-company-Numeric.csv\", delimiter = ',')[:8]\n",
    "lending_co_data_numeric\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1. With np.shuffle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1st way to sfuffle\n",
    "\n",
    "# Shuffles the array and changes in place\n",
    "\n",
    "np.random.shuffle(lending_co_data_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1000.,    40.,   365.,  2160.,  3280., 15340.],\n",
       "       [ 2000.,    50.,   365.,  3470.,  4820., 13720.],\n",
       "       [ 2000.,    40.,   365.,  3971.,  4131., 15351.],\n",
       "       [ 2000.,    50.,   365.,  1851.,  3251., 17701.],\n",
       "       [ 2000.,    40.,   365.,  3201.,  4141., 14141.],\n",
       "       [ 2000.,    40.,   365.,  3121.,  4241., 13621.],\n",
       "       [ 2000.,    40.,   365.,  3041.,  4241., 15321.],\n",
       "       [ 2000.,    40.,   365.,  3061.,  4171., 15041.]])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lending_co_data_numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2000.,    40.,   365.,  3971.,  4131., 15351.],\n",
       "       [ 2000.,    50.,   365.,  3470.,  4820., 13720.],\n",
       "       [ 1000.,    40.,   365.,  2160.,  3280., 15340.],\n",
       "       [ 2000.,    40.,   365.,  3041.,  4241., 15321.],\n",
       "       [ 2000.,    40.,   365.,  3121.,  4241., 13621.],\n",
       "       [ 2000.,    40.,   365.,  3061.,  4171., 15041.],\n",
       "       [ 2000.,    40.,   365.,  3201.,  4141., 14141.],\n",
       "       [ 2000.,    50.,   365.,  1851.,  3251., 17701.]])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can shuffle the array as many times as we wish \n",
    "\n",
    "np.random.shuffle(lending_co_data_numeric)\n",
    "lending_co_data_numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2000.,    40.,   365.,  3121.,  4241., 13621.],\n",
       "       [ 2000.,    40.,   365.,  3061.,  4171., 15041.],\n",
       "       [ 1000.,    40.,   365.,  2160.,  3280., 15340.],\n",
       "       ...,\n",
       "       [ 2000.,    40.,   365.,  4201.,  5001., 16600.],\n",
       "       [ 1000.,    40.,   365.,  2080.,  3320., 15600.],\n",
       "       [ 2000.,    40.,   365.,  4601.,  4601., 16600.]])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now, let's load entire dataset and apply function to entire dataset\n",
    "\n",
    "lending_co_data_numeric = np.loadtxt(\"Lending-company-Numeric.csv\", delimiter = ',')\n",
    "lending_co_data_numeric\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can import functions we use multiple times for convenience\n",
    "\n",
    "from numpy.random import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2000.,    40.,   365.,  3240.,  4120., 12570.],\n",
       "       [ 4000.,    50.,   365.,  9500., 18250., 22250.],\n",
       "       [ 2000.,    40.,   365.,  3401.,  4601., 16600.],\n",
       "       ...,\n",
       "       [ 2000.,    40.,   365.,  3401.,  3401., 12921.],\n",
       "       [ 2000.,    50.,   365.,  3951.,  4951., 14251.],\n",
       "       [ 1000.,    50.,   365.,   750.,  2100., 12100.]])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shuffle(lending_co_data_numeric)\n",
    "lending_co_data_numeric\n",
    "\n",
    "# We write shuffle() instead of numpy.random.shuffle() since we imported the function earlier. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2. With random generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import Generator as gen\n",
    "from numpy.random import PCG64 as pcg\n",
    "\n",
    "# Random generators can be used for shuffling. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1000.,    50.,   365.,  1250.,  2250., 13800.],\n",
       "       [ 2000.,    40.,   365.,  3601.,  4441., 15691.],\n",
       "       [ 2000.,    40.,   365.,  3701.,  6701., 16600.],\n",
       "       ...,\n",
       "       [ 2000.,    40.,   365.,  3600.,  4240., 16600.],\n",
       "       [ 4000.,    50.,   365.,  7350.,  7350., 22250.],\n",
       "       [ 4000.,    50.,   365.,  4900.,  5650., 10100.]])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array_RG = gen(pcg(seed = 365))\n",
    "array_RG.shuffle(lending_co_data_numeric)\n",
    "lending_co_data_numeric\n",
    "\n",
    "# Seeds don't work for shuffling (and it's intended)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Type Casting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take object with values of certain datatype &\n",
    "create object with identical values of different datatype.\n",
    "\n",
    "With astype() = assign type\n",
    "\n",
    "Ex: change float to integer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2000.,    40.,   365.,  3121.,  4241., 13621.],\n",
       "       [ 2000.,    40.,   365.,  3061.,  4171., 15041.],\n",
       "       [ 1000.,    40.,   365.,  2160.,  3280., 15340.],\n",
       "       ...,\n",
       "       [ 2000.,    40.,   365.,  4201.,  5001., 16600.],\n",
       "       [ 1000.,    40.,   365.,  2080.,  3320., 15600.],\n",
       "       [ 2000.,    40.,   365.,  4601.,  4601., 16600.]])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load dataset\n",
    "\n",
    "lending_co_data_numeric = np.loadtxt(\"Lending-company-Numeric.csv\", delimiter = ',') \n",
    "lending_co_data_numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2000,    40,   365,  3121,  4241, 13621],\n",
       "       [ 2000,    40,   365,  3061,  4171, 15041],\n",
       "       [ 1000,    40,   365,  2160,  3280, 15340],\n",
       "       ...,\n",
       "       [ 2000,    40,   365,  4201,  5001, 16600],\n",
       "       [ 1000,    40,   365,  2080,  3320, 15600],\n",
       "       [ 2000,    40,   365,  4601,  4601, 16600]], dtype=int32)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Typecast float -> integer : OK\n",
    "\n",
    "lending_co_data_numeric.astype(dtype = np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2000.,    40.,   365.,  3121.,  4241., 13621.],\n",
       "       [ 2000.,    40.,   365.,  3061.,  4171., 15041.],\n",
       "       [ 1000.,    40.,   365.,  2160.,  3280., 15340.],\n",
       "       ...,\n",
       "       [ 2000.,    40.,   365.,  4201.,  5001., 16600.],\n",
       "       [ 1000.,    40.,   365.,  2080.,  3320., 15600.],\n",
       "       [ 2000.,    40.,   365.,  4601.,  4601., 16600.]])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# astype() does not change values in place\n",
    "\n",
    "lending_co_data_numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['2000', '40', '365', '3121', '4241', '13621'],\n",
       "       ['2000', '40', '365', '3061', '4171', '15041'],\n",
       "       ['1000', '40', '365', '2160', '3280', '15340'],\n",
       "       ...,\n",
       "       ['2000', '40', '365', '4201', '5001', '16600'],\n",
       "       ['1000', '40', '365', '2080', '3320', '15600'],\n",
       "       ['2000', '40', '365', '4601', '4601', '16600']], dtype='<U11')"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Typecast integer -> str : NOT OK\n",
    "\n",
    "lending_co_data_numeric.astype(dtype = np.int32).astype(dtype = np.str_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Typecast float -> str : OK\n",
    "# overwrite variable\n",
    "\n",
    "lending_co_data_numeric = lending_co_data_numeric.astype(dtype = np.str_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['2000.0', '40.0', '365.0', '3121.0', '4241.0', '13621.0'],\n",
       "       ['2000.0', '40.0', '365.0', '3061.0', '4171.0', '15041.0'],\n",
       "       ['1000.0', '40.0', '365.0', '2160.0', '3280.0', '15340.0'],\n",
       "       ...,\n",
       "       ['2000.0', '40.0', '365.0', '4201.0', '5001.0', '16600.0'],\n",
       "       ['1000.0', '40.0', '365.0', '2080.0', '3320.0', '15600.0'],\n",
       "       ['2000.0', '40.0', '365.0', '4601.0', '4601.0', '16600.0']],\n",
       "      dtype='<U32')"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lending_co_data_numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: np.str_('2000.0')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[93], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Typecast str -> int: NOT OK\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[43mlending_co_data_numeric\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mint32\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: np.str_('2000.0')"
     ]
    }
   ],
   "source": [
    "# Typecast str -> int: NOT OK\n",
    "\n",
    "lending_co_data_numeric.astype(dtype = np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2000,    40,   365,  3121,  4241, 13621],\n",
       "       [ 2000,    40,   365,  3061,  4171, 15041],\n",
       "       [ 1000,    40,   365,  2160,  3280, 15340],\n",
       "       ...,\n",
       "       [ 2000,    40,   365,  4201,  5001, 16600],\n",
       "       [ 1000,    40,   365,  2080,  3320, 15600],\n",
       "       [ 2000,    40,   365,  4601,  4601, 16600]], dtype=int32)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# So only possible if we go through floats: string -> float -> integer\n",
    "# or:                                       string <- float <- integer\n",
    "\n",
    "lending_co_data_numeric = lending_co_data_numeric.astype(dtype = np.float32)\n",
    "lending_co_data_numeric.astype(dtype = np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2000,    40,   365,  3121,  4241, 13621],\n",
       "       [ 2000,    40,   365,  3061,  4171, 15041],\n",
       "       [ 1000,    40,   365,  2160,  3280, 15340],\n",
       "       ...,\n",
       "       [ 2000,    40,   365,  4201,  5001, 16600],\n",
       "       [ 1000,    40,   365,  2080,  3320, 15600],\n",
       "       [ 2000,    40,   365,  4601,  4601, 16600]], dtype=int32)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can chain methods in NumPy\n",
    "\n",
    "lending_co_data_numeric.astype(dtype = np.float32).astype(dtype = np.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Stripping Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### np.char.strip()\n",
    "\n",
    "remove excess parts of string data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['id_1', 'Product B', 'Location 2'],\n",
       "       ['id_2', 'Product B', 'Location 3'],\n",
       "       ['id_3', 'Product C', 'Location 5'],\n",
       "       ...,\n",
       "       ['id_413', 'Product B', 'Location 135'],\n",
       "       ['id_414', 'Product C', 'Location 200'],\n",
       "       ['id_415', 'Product A', 'Location 8']], dtype='<U12')"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load dataset\n",
    "# only load text data in columns with index 1,2,4\n",
    "\n",
    "lending_co_total_price = np.genfromtxt(\"Lending-Company-Total-Price.csv\",\n",
    "                                       delimiter = ',',\n",
    "                                       dtype = np.str_,\n",
    "                                       skip_header = 1, \n",
    "                                       usecols = [1,2,4])\n",
    "lending_co_total_price\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['1', 'B', '2'],\n",
       "       ['2', 'B', '3'],\n",
       "       ['3', 'C', '5'],\n",
       "       ...,\n",
       "       ['413', 'B', '135'],\n",
       "       ['414', 'C', '200'],\n",
       "       ['415', 'A', '8']], dtype='<U12')"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove \"id_\" from the 1st column,\n",
    "# as well as \"Product \" from the second column,\n",
    "# and \"Location \" from the third one. \n",
    "\n",
    "lending_co_total_price[:,0] = np.char.strip(lending_co_total_price[:,0], \"id_\")\n",
    "lending_co_total_price[:,1] = np.char.strip(lending_co_total_price[:,1], \"Product \")\n",
    "lending_co_total_price[:,2] = np.char.strip(lending_co_total_price[:,2], \"Location \")\n",
    "lending_co_total_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['1', '2', '2'],\n",
       "       ['2', '2', '3'],\n",
       "       ['3', '3', '5'],\n",
       "       ...,\n",
       "       ['413', '2', '135'],\n",
       "       ['414', '3', '200'],\n",
       "       ['415', '1', '8']], dtype='<U12')"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can combine stripping with substituting to transform all the letters in numbers\n",
    "\n",
    "lending_co_total_price[:,1] = np.where(lending_co_total_price[:,1] == 'A', '1', lending_co_total_price[:,1]) \n",
    "lending_co_total_price[:,1] = np.where(lending_co_total_price[:,1] == 'B', '2', lending_co_total_price[:,1]) \n",
    "lending_co_total_price[:,1] = np.where(lending_co_total_price[:,1] == 'C', '3', lending_co_total_price[:,1]) \n",
    "lending_co_total_price[:,1] = np.where(lending_co_total_price[:,1] == 'D', '4', lending_co_total_price[:,1]) \n",
    "lending_co_total_price[:,1] = np.where(lending_co_total_price[:,1] == 'E', '5', lending_co_total_price[:,1]) \n",
    "lending_co_total_price[:,1] = np.where(lending_co_total_price[:,1] == 'F', '6', lending_co_total_price[:,1]) \n",
    "\n",
    "lending_co_total_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1,   2,   2],\n",
       "       [  2,   2,   3],\n",
       "       [  3,   3,   5],\n",
       "       ...,\n",
       "       [413,   2, 135],\n",
       "       [414,   3, 200],\n",
       "       [415,   1,   8]], dtype=int32)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Even though the values look like numbers, they're actually just text, so we need to cast them once again. \n",
    "\n",
    "lending_co_total_price = lending_co_total_price.astype(dtype = np.int32)\n",
    "lending_co_total_price\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Stacking\n",
    "\n",
    "    placing multiple arrays of matching shapes on top of another\n",
    "    to create larger array\n",
    "\n",
    "    9.1. np.stack()\n",
    "    9.2. np.vstack()\n",
    "    9.3. np.hstack()\n",
    "    9.4. np.dstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2000.,    40.,   365.,  3121.,  4241., 13621.],\n",
       "       [ 2000.,    40.,   365.,  3061.,  4171., 15041.],\n",
       "       [ 1000.,    40.,   365.,  2160.,  3280., 15340.],\n",
       "       ...,\n",
       "       [ 2000.,    40.,   365.,  4201.,  5001., 16600.],\n",
       "       [ 1000.,    40.,   365.,  2080.,  3320., 15600.],\n",
       "       [ 2000.,    40.,   365.,  4601.,  4601., 16600.]])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load dataset\n",
    "\n",
    "# dataset 1: no nan\n",
    "\n",
    "lending_co_data_numeric = np.loadtxt(\"Lending-company-Numeric.csv\", delimiter = ',') \n",
    "lending_co_data_numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2000.  ,    40.  ,   365.  ,  3121.  ,  4241.  , 13621.  ],\n",
       "       [ 2000.  ,    40.  ,   365.  ,  3061.  ,  4171.  , 15041.  ],\n",
       "       [ 1000.  ,    40.  ,   365.  ,  2160.  ,  3280.  , 15340.  ],\n",
       "       ...,\n",
       "       [ 2250.25,    40.  ,   365.  ,  4201.  ,  5001.  , 16600.  ],\n",
       "       [ 1000.  ,    40.  ,   365.  ,  2080.  ,  3320.  , 15600.  ],\n",
       "       [ 2000.  ,    40.  ,   365.  ,  4601.  ,  4601.  , 16600.  ]])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataset 2: with nan\n",
    "\n",
    "# Recall\n",
    "# We create a filler, reimport and fill all the nan-s, \n",
    "# then subsitute all the temporary fillers with more appropriate values\n",
    "\n",
    "lending_co_data_numeric_NAN = np.genfromtxt(\"Lending-company-Numeric-NAN.csv\", delimiter = ';')\n",
    "\n",
    "temporary_fill = np.nanmax(lending_co_data_numeric_NAN).round(2) + 1\n",
    "temporary_mean = np.nanmean(lending_co_data_numeric_NAN, axis = 0).round(2)\n",
    "\n",
    "lending_co_data_numeric_NAN = np.genfromtxt(\"Lending-company-Numeric-NAN.csv\", \n",
    "                                            delimiter = ';', \n",
    "                                            filling_values = temporary_fill)\n",
    "\n",
    "for i in range(lending_co_data_numeric_NAN.shape[1]):\n",
    "    lending_co_data_numeric_NAN[:,i] = np.where(lending_co_data_numeric_NAN[:,i] == temporary_fill,\n",
    "                                                temporary_mean[i],\n",
    "                                                lending_co_data_numeric_NAN[:,i])\n",
    "lending_co_data_numeric_NAN\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.1. np.stack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  40.,   40.,   40., ...,   40.,   40.,   40.],\n",
       "       [2000., 2000., 1000., ..., 2000., 1000., 2000.]])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# stacking the first 2 columns on top of each other\n",
    "\n",
    "np.stack((lending_co_data_numeric[:,1],lending_co_data_numeric[:,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2000., 2000., 1000., ..., 2000., 1000., 2000.],\n",
       "       [  40.,   40.,   40., ...,   40.,   40.,   40.]])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can stack them in any order we like: first mentioned array comes on top\n",
    "\n",
    "np.stack((lending_co_data_numeric[:,0],lending_co_data_numeric[:,1])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2000., 2000., 1000., ..., 2000., 1000., 2000.],\n",
       "       [  40.,   40.,   40., ...,   40.,   40.,   40.]])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# comparable output as transposing only the first two columns\n",
    "\n",
    "np.transpose(lending_co_data_numeric[:,:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2000.,   40.],\n",
       "       [2000.,   40.],\n",
       "       [1000.,   40.],\n",
       "       ...,\n",
       "       [2000.,   40.],\n",
       "       [1000.,   40.],\n",
       "       [2000.,   40.]])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can also put them side by side instead of on top of each other\n",
    "# by setting axis parameter to 1\n",
    "\n",
    "np.stack((lending_co_data_numeric[:,0],lending_co_data_numeric[:,1]), axis = 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2000.,   40.,  365.],\n",
       "       [2000.,   40.,  365.],\n",
       "       [1000.,   40.,  365.],\n",
       "       ...,\n",
       "       [2000.,   40.,  365.],\n",
       "       [1000.,   40.,  365.],\n",
       "       [2000.,   40.,  365.]])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can stack more than 2 arrays\n",
    "\n",
    "np.stack((lending_co_data_numeric[:,0],lending_co_data_numeric[:,1], lending_co_data_numeric[:,2]), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "all input arrays must have the same shape",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[107], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# however to stack arrays must have same shape \u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# we change last array to width of 2 columns, while first 2 arrays keep width of 1 column\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlending_co_data_numeric\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mlending_co_data_numeric\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlending_co_data_numeric\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# this returns a value error\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/Udemy_NumPy/lib/python3.13/site-packages/numpy/_core/shape_base.py:457\u001b[0m, in \u001b[0;36mstack\u001b[0;34m(arrays, axis, out, dtype, casting)\u001b[0m\n\u001b[1;32m    455\u001b[0m shapes \u001b[38;5;241m=\u001b[39m {arr\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;28;01mfor\u001b[39;00m arr \u001b[38;5;129;01min\u001b[39;00m arrays}\n\u001b[1;32m    456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(shapes) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 457\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mall input arrays must have the same shape\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    459\u001b[0m result_ndim \u001b[38;5;241m=\u001b[39m arrays[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    460\u001b[0m axis \u001b[38;5;241m=\u001b[39m normalize_axis_index(axis, result_ndim)\n",
      "\u001b[0;31mValueError\u001b[0m: all input arrays must have the same shape"
     ]
    }
   ],
   "source": [
    "# however to stack arrays must have same shape \n",
    "# we change last array to width of 2 columns, while first 2 arrays keep width of 1 column\n",
    "\n",
    "np.stack((lending_co_data_numeric[:,0],lending_co_data_numeric[:,1], lending_co_data_numeric[:,:2]), axis = 1)\n",
    "\n",
    "# this returns a value error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.2. np.vstack()\n",
    "\n",
    "    v stack = vertical stack\n",
    "    place first array vertically on top of other array\n",
    "    results in a 'long' array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1043, 6) (1043, 6)\n"
     ]
    }
   ],
   "source": [
    "# both datasets we loaded have same shape, so we can stack them\n",
    "\n",
    "print(lending_co_data_numeric.shape, lending_co_data_numeric_NAN.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2000.  ,    40.  ,   365.  ,  3121.  ,  4241.  , 13621.  ],\n",
       "       [ 2000.  ,    40.  ,   365.  ,  3061.  ,  4171.  , 15041.  ],\n",
       "       [ 1000.  ,    40.  ,   365.  ,  2160.  ,  3280.  , 15340.  ],\n",
       "       ...,\n",
       "       [ 2250.25,    40.  ,   365.  ,  4201.  ,  5001.  , 16600.  ],\n",
       "       [ 1000.  ,    40.  ,   365.  ,  2080.  ,  3320.  , 15600.  ],\n",
       "       [ 2000.  ,    40.  ,   365.  ,  4601.  ,  4601.  , 16600.  ]])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.vstack((lending_co_data_numeric, lending_co_data_numeric_NAN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2086, 6)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# visually the output does not allow us to see that the datasets are vertically stacked\n",
    "# but we know that each of them contains 1043 rows\n",
    "# and when we call the .shape attribute we see that the new array has indeed 2x1043 = 2086 rows\n",
    "\n",
    "np.vstack((lending_co_data_numeric, lending_co_data_numeric_NAN)).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.3. np.hstack()\n",
    "\n",
    "    h stack = horizontal stack\n",
    "    place first array horizontally next to other array\n",
    "    results in a 'wider' array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2000.,    40.,   365., ...,  3121.,  4241., 13621.],\n",
       "       [ 2000.,    40.,   365., ...,  3061.,  4171., 15041.],\n",
       "       [ 1000.,    40.,   365., ...,  2160.,  3280., 15340.],\n",
       "       ...,\n",
       "       [ 2000.,    40.,   365., ...,  4201.,  5001., 16600.],\n",
       "       [ 1000.,    40.,   365., ...,  2080.,  3320., 15600.],\n",
       "       [ 2000.,    40.,   365., ...,  4601.,  4601., 16600.]])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.hstack((lending_co_data_numeric, lending_co_data_numeric_NAN)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1043, 12)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# again, when calling the .shape attribute we can see that the\n",
    "# new array has 2x6 = 12 columns\n",
    "\n",
    "np.hstack((lending_co_data_numeric, lending_co_data_numeric_NAN)).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.4. np.dstack()\n",
    "\n",
    "    d stack = depth stack\n",
    "    stack arrays in an extra dimension\n",
    "    results in array of a higher dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 2000.  ,  2000.  ],\n",
       "        [   40.  ,    40.  ],\n",
       "        [  365.  ,   365.  ],\n",
       "        [ 3121.  ,  3121.  ],\n",
       "        [ 4241.  ,  4241.  ],\n",
       "        [13621.  , 13621.  ]],\n",
       "\n",
       "       [[ 2000.  ,  2000.  ],\n",
       "        [   40.  ,    40.  ],\n",
       "        [  365.  ,   365.  ],\n",
       "        [ 3061.  ,  3061.  ],\n",
       "        [ 4171.  ,  4171.  ],\n",
       "        [15041.  , 15041.  ]],\n",
       "\n",
       "       [[ 1000.  ,  1000.  ],\n",
       "        [   40.  ,    40.  ],\n",
       "        [  365.  ,   365.  ],\n",
       "        [ 2160.  ,  2160.  ],\n",
       "        [ 3280.  ,  3280.  ],\n",
       "        [15340.  , 15340.  ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 2000.  ,  2250.25],\n",
       "        [   40.  ,    40.  ],\n",
       "        [  365.  ,   365.  ],\n",
       "        [ 4201.  ,  4201.  ],\n",
       "        [ 5001.  ,  5001.  ],\n",
       "        [16600.  , 16600.  ]],\n",
       "\n",
       "       [[ 1000.  ,  1000.  ],\n",
       "        [   40.  ,    40.  ],\n",
       "        [  365.  ,   365.  ],\n",
       "        [ 2080.  ,  2080.  ],\n",
       "        [ 3320.  ,  3320.  ],\n",
       "        [15600.  , 15600.  ]],\n",
       "\n",
       "       [[ 2000.  ,  2000.  ],\n",
       "        [   40.  ,    40.  ],\n",
       "        [  365.  ,   365.  ],\n",
       "        [ 4601.  ,  4601.  ],\n",
       "        [ 4601.  ,  4601.  ],\n",
       "        [16600.  , 16600.  ]]])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dstack((lending_co_data_numeric, lending_co_data_numeric_NAN)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1043, 6, 2)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we have 3-D array consisting of multiple (6,2) arrays\n",
    "\n",
    "np.dstack((lending_co_data_numeric, lending_co_data_numeric_NAN)).shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2000.,  2000.],\n",
       "       [   40.,    40.],\n",
       "       [  365.,   365.],\n",
       "       [ 3121.,  3121.],\n",
       "       [ 4241.,  4241.],\n",
       "       [13621., 13621.]])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# think of dimensions as: first element is row, second column, third original array\n",
    "# isolate first dimension: represents row\n",
    "\n",
    "np.dstack((lending_co_data_numeric, lending_co_data_numeric_NAN))[0]\n",
    "\n",
    "# each column contains first row of a dataset, and first rows of both datasets are stacked together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2000., 2000.])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# isolate second dimension: refers to the columns of either input array\n",
    "\n",
    "np.dstack((lending_co_data_numeric, lending_co_data_numeric_NAN))[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2000.,    40.,   365.,  3121.,  4241., 13621.])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# isolate third dimension: slice all columns with row index 0 and depth index 0\n",
    "\n",
    "np.dstack((lending_co_data_numeric, lending_co_data_numeric_NAN))[0,:,0]\n",
    "\n",
    "# we see the data of first row from only 1 array\n",
    "# this third dimension refers to the oroginal array the data come from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 2000.  ,  2000.  ],\n",
       "        [   40.  ,    40.  ],\n",
       "        [  365.  ,   365.  ],\n",
       "        [ 3121.  ,  3121.  ],\n",
       "        [ 4241.  ,  4241.  ],\n",
       "        [13621.  , 13621.  ]],\n",
       "\n",
       "       [[ 2000.  ,  2000.  ],\n",
       "        [   40.  ,    40.  ],\n",
       "        [  365.  ,   365.  ],\n",
       "        [ 3061.  ,  3061.  ],\n",
       "        [ 4171.  ,  4171.  ],\n",
       "        [15041.  , 15041.  ]],\n",
       "\n",
       "       [[ 1000.  ,  1000.  ],\n",
       "        [   40.  ,    40.  ],\n",
       "        [  365.  ,   365.  ],\n",
       "        [ 2160.  ,  2160.  ],\n",
       "        [ 3280.  ,  3280.  ],\n",
       "        [15340.  , 15340.  ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 2000.  ,  2250.25],\n",
       "        [   40.  ,    40.  ],\n",
       "        [  365.  ,   365.  ],\n",
       "        [ 4201.  ,  4201.  ],\n",
       "        [ 5001.  ,  5001.  ],\n",
       "        [16600.  , 16600.  ]],\n",
       "\n",
       "       [[ 1000.  ,  1000.  ],\n",
       "        [   40.  ,    40.  ],\n",
       "        [  365.  ,   365.  ],\n",
       "        [ 2080.  ,  2080.  ],\n",
       "        [ 3320.  ,  3320.  ],\n",
       "        [15600.  , 15600.  ]],\n",
       "\n",
       "       [[ 2000.  ,  2000.  ],\n",
       "        [   40.  ,    40.  ],\n",
       "        [  365.  ,   365.  ],\n",
       "        [ 4601.  ,  4601.  ],\n",
       "        [ 4601.  ,  4601.  ],\n",
       "        [16600.  , 16600.  ]]])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# with np.stack we can get same output if we set axis = -1\n",
    "# a stack function returns an output that is exactly 1 dimension more than its inputs\n",
    "\n",
    "\n",
    "np.stack((lending_co_data_numeric, lending_co_data_numeric_NAN), axis = -1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only in 1-D and 2-D arrays do np.stack and np.dstack give the same output\n",
    "# for higher dimensional arrays this is no longer the case\n",
    "# We reate 2 3-D arrays to showcase how dstack works for higher dimensions, to illustrate this:\n",
    "\n",
    "array_example_1 = np.array([[[1,2,3,4],[5,6,7,8],[9,10,11,12]],[[21,22,23,24],[25,26,27,28],[29,30,31,32]]])\n",
    "array_example_2 = array_example_1 * 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 1,  2,  3,  4,  2,  4,  6,  8],\n",
       "        [ 5,  6,  7,  8, 10, 12, 14, 16],\n",
       "        [ 9, 10, 11, 12, 18, 20, 22, 24]],\n",
       "\n",
       "       [[21, 22, 23, 24, 42, 44, 46, 48],\n",
       "        [25, 26, 27, 28, 50, 52, 54, 56],\n",
       "        [29, 30, 31, 32, 58, 60, 62, 64]]])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now we call dstack\n",
    "\n",
    "np.dstack((array_example_1, array_example_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ 1,  2],\n",
       "         [ 2,  4],\n",
       "         [ 3,  6],\n",
       "         [ 4,  8]],\n",
       "\n",
       "        [[ 5, 10],\n",
       "         [ 6, 12],\n",
       "         [ 7, 14],\n",
       "         [ 8, 16]],\n",
       "\n",
       "        [[ 9, 18],\n",
       "         [10, 20],\n",
       "         [11, 22],\n",
       "         [12, 24]]],\n",
       "\n",
       "\n",
       "       [[[21, 42],\n",
       "         [22, 44],\n",
       "         [23, 46],\n",
       "         [24, 48]],\n",
       "\n",
       "        [[25, 50],\n",
       "         [26, 52],\n",
       "         [27, 54],\n",
       "         [28, 56]],\n",
       "\n",
       "        [[29, 58],\n",
       "         [30, 60],\n",
       "         [31, 62],\n",
       "         [32, 64]]]])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# as well as stack\n",
    "\n",
    "np.stack((array_example_1, array_example_2), axis = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 3, 8)\n",
      "(2, 3, 4, 2)\n"
     ]
    }
   ],
   "source": [
    "# and we see we get different outcomes\n",
    "# we can verify this by calling the .shape attribute again\n",
    "\n",
    "print(np.dstack((array_example_1, array_example_2)).shape)\n",
    "print(np.stack((array_example_1, array_example_2), axis = -1).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Concatenate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    link together arrays in a chain along a given axis\n",
    "    inputs and outputs of concatenate() function have same nr of dimensions\n",
    "    (which makes it different from stack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2000.,    40.,   365.,  3121.,  4241., 13621.],\n",
       "       [ 2000.,    40.,   365.,  3061.,  4171., 15041.],\n",
       "       [ 1000.,    40.,   365.,  2160.,  3280., 15340.],\n",
       "       ...,\n",
       "       [ 2000.,    40.,   365.,  4201.,  5001., 16600.],\n",
       "       [ 1000.,    40.,   365.,  2080.,  3320., 15600.],\n",
       "       [ 2000.,    40.,   365.,  4601.,  4601., 16600.]])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load dataset\n",
    "\n",
    "lending_co_data_numeric = np.loadtxt(\"Lending-company-Numeric.csv\", delimiter = ',') \n",
    "lending_co_data_numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2000.,    40.,   365.,  3121.,  4241., 13621.,  2000.,    40.,\n",
       "         365.,  3061.,  4171., 15041.])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The concatenated array has the same number of dimensions as the inputs\n",
    "\n",
    "np.concatenate((lending_co_data_numeric[0,:], lending_co_data_numeric[1,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2000.  ,    40.  ,   365.  ,  3121.  ,  4241.  , 13621.  ],\n",
       "       [ 2000.  ,    40.  ,   365.  ,  3061.  ,  4171.  , 15041.  ],\n",
       "       [ 1000.  ,    40.  ,   365.  ,  2160.  ,  3280.  , 15340.  ],\n",
       "       ...,\n",
       "       [ 2250.25,    40.  ,   365.  ,  4201.  ,  5001.  , 16600.  ],\n",
       "       [ 1000.  ,    40.  ,   365.  ,  2080.  ,  3320.  , 15600.  ],\n",
       "       [ 2000.  ,    40.  ,   365.  ,  4601.  ,  4601.  , 16600.  ]])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's see how concatenation works for 2 arrays\n",
    "# create another 2-D array\n",
    "\n",
    "#Recall: \n",
    "    \n",
    "lending_co_data_numeric_NAN = np.genfromtxt(\"Lending-company-Numeric-NAN.csv\", delimiter = ';')\n",
    "\n",
    "temporary_fill = np.nanmax(lending_co_data_numeric_NAN).round(2) + 1\n",
    "temporary_mean = np.nanmean(lending_co_data_numeric_NAN, axis = 0).round(2)\n",
    "\n",
    "lending_co_data_numeric_NAN = np.genfromtxt(\"Lending-company-Numeric-NAN.csv\",\n",
    "                                            delimiter = ';', \n",
    "                                            filling_values = temporary_fill)\n",
    "\n",
    "for i in range(lending_co_data_numeric_NAN.shape[1]):        \n",
    "    lending_co_data_numeric_NAN[:,i] = np.where(lending_co_data_numeric_NAN[:,i] == temporary_fill,\n",
    "                                                temporary_mean[i],\n",
    "                                                lending_co_data_numeric_NAN[:,i])\n",
    "    \n",
    "lending_co_data_numeric_NAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2000.  ,    40.  ,   365.  ,  3121.  ,  4241.  , 13621.  ],\n",
       "       [ 2000.  ,    40.  ,   365.  ,  3061.  ,  4171.  , 15041.  ],\n",
       "       [ 1000.  ,    40.  ,   365.  ,  2160.  ,  3280.  , 15340.  ],\n",
       "       ...,\n",
       "       [ 2250.25,    40.  ,   365.  ,  4201.  ,  5001.  , 16600.  ],\n",
       "       [ 1000.  ,    40.  ,   365.  ,  2080.  ,  3320.  , 15600.  ],\n",
       "       [ 2000.  ,    40.  ,   365.  ,  4601.  ,  4601.  , 16600.  ]])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# concatenate old and new dataset\n",
    "\n",
    "np.concatenate((lending_co_data_numeric, lending_co_data_numeric_NAN))\n",
    "\n",
    "# we've concatenated second dataset at bottom of first\n",
    "# check third lowest row, first column: identical with second dataset above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2086, 6)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can check by calling .shape attribute: indeed 2x1043 = 2086 rows\n",
    "\n",
    "np.concatenate((lending_co_data_numeric, lending_co_data_numeric_NAN)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2000.,    40.,   365., ...,  3121.,  4241., 13621.],\n",
       "       [ 2000.,    40.,   365., ...,  3061.,  4171., 15041.],\n",
       "       [ 1000.,    40.,   365., ...,  2160.,  3280., 15340.],\n",
       "       ...,\n",
       "       [ 2000.,    40.,   365., ...,  4201.,  5001., 16600.],\n",
       "       [ 1000.,    40.,   365., ...,  2080.,  3320., 15600.],\n",
       "       [ 2000.,    40.,   365., ...,  4601.,  4601., 16600.]])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can also concatenate per dimension: along second axis = 1\n",
    "\n",
    "np.concatenate((lending_co_data_numeric, lending_co_data_numeric_NAN), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1043, 12)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# horizontal concatenation: 6 rows + 6 rows wide\n",
    "\n",
    "np.concatenate((lending_co_data_numeric, lending_co_data_numeric_NAN), axis = 1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2000.  ,    40.  ,   365.  ,  3121.  ,  4241.  , 13621.  ],\n",
       "       [ 2000.  ,    40.  ,   365.  ,  3061.  ,  4171.  , 15041.  ],\n",
       "       [ 1000.  ,    40.  ,   365.  ,  2160.  ,  3280.  , 15340.  ],\n",
       "       ...,\n",
       "       [ 2250.25,    40.  ,   365.  ,  4201.  ,  5001.  , 16600.  ],\n",
       "       [ 1000.  ,    40.  ,   365.  ,  2080.  ,  3320.  , 15600.  ],\n",
       "       [ 2000.  ,    40.  ,   365.  ,  4601.  ,  4601.  , 16600.  ]])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can also concatenate per dimension: along first axis = 0 : this is the default way of concatenating\n",
    "# vertical: see above\n",
    "\n",
    "np.concatenate((lending_co_data_numeric, lending_co_data_numeric_NAN), axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2086, 6)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.concatenate((lending_co_data_numeric, lending_co_data_numeric_NAN), axis = 0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what happens in higher dimensions?\n",
    "# We create 3-D arrays to showcase concatenate vs stacking\n",
    "\n",
    "array_example_1 = np.array([[[1,2,3,4],[5,6,7,8],[9,10,11,12]],[[21,22,23,24],[25,26,27,28],[29,30,31,32]]])\n",
    "array_example_2 = array_example_1 * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 1,  2,  3,  4],\n",
       "        [ 5,  6,  7,  8],\n",
       "        [ 9, 10, 11, 12]],\n",
       "\n",
       "       [[21, 22, 23, 24],\n",
       "        [25, 26, 27, 28],\n",
       "        [29, 30, 31, 32]],\n",
       "\n",
       "       [[ 2,  4,  6,  8],\n",
       "        [10, 12, 14, 16],\n",
       "        [18, 20, 22, 24]],\n",
       "\n",
       "       [[42, 44, 46, 48],\n",
       "        [50, 52, 54, 56],\n",
       "        [58, 60, 62, 64]]])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.concatenate((array_example_1, array_example_2), axis = 0) \n",
    "# same as = vstack((array_example_1, array_example_2))\n",
    "\n",
    "# np.concatenate((array_example_1, array_example_2), axis = 1) \n",
    "# same as = hstack((array_example_1, array_example_2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 1,  2,  3,  4],\n",
       "        [ 5,  6,  7,  8],\n",
       "        [ 9, 10, 11, 12]],\n",
       "\n",
       "       [[21, 22, 23, 24],\n",
       "        [25, 26, 27, 28],\n",
       "        [29, 30, 31, 32]],\n",
       "\n",
       "       [[ 2,  4,  6,  8],\n",
       "        [10, 12, 14, 16],\n",
       "        [18, 20, 22, 24]],\n",
       "\n",
       "       [[42, 44, 46, 48],\n",
       "        [50, 52, 54, 56],\n",
       "        [58, 60, 62, 64]]])"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# same as = np.vstack((array_example_1, array_example_2))\n",
    "\n",
    "np.vstack((array_example_1, array_example_2)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 1,  2,  3,  4],\n",
       "        [ 5,  6,  7,  8],\n",
       "        [ 9, 10, 11, 12],\n",
       "        [ 2,  4,  6,  8],\n",
       "        [10, 12, 14, 16],\n",
       "        [18, 20, 22, 24]],\n",
       "\n",
       "       [[21, 22, 23, 24],\n",
       "        [25, 26, 27, 28],\n",
       "        [29, 30, 31, 32],\n",
       "        [42, 44, 46, 48],\n",
       "        [50, 52, 54, 56],\n",
       "        [58, 60, 62, 64]]])"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.concatenate((array_example_1, array_example_2), axis = 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 1,  2,  3,  4],\n",
       "        [ 5,  6,  7,  8],\n",
       "        [ 9, 10, 11, 12],\n",
       "        [ 2,  4,  6,  8],\n",
       "        [10, 12, 14, 16],\n",
       "        [18, 20, 22, 24]],\n",
       "\n",
       "       [[21, 22, 23, 24],\n",
       "        [25, 26, 27, 28],\n",
       "        [29, 30, 31, 32],\n",
       "        [42, 44, 46, 48],\n",
       "        [50, 52, 54, 56],\n",
       "        [58, 60, 62, 64]]])"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# same as = np.hstack((array_example_1, array_example_2))\n",
    "\n",
    "np.hstack((array_example_1, array_example_2)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 1,  2,  3,  4,  2,  4,  6,  8],\n",
       "        [ 5,  6,  7,  8, 10, 12, 14, 16],\n",
       "        [ 9, 10, 11, 12, 18, 20, 22, 24]],\n",
       "\n",
       "       [[21, 22, 23, 24, 42, 44, 46, 48],\n",
       "        [25, 26, 27, 28, 50, 52, 54, 56],\n",
       "        [29, 30, 31, 32, 58, 60, 62, 64]]])"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# and what happens when we set axis = 2?\n",
    "np.concatenate((array_example_1, array_example_2), axis = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 1,  2,  3,  4,  2,  4,  6,  8],\n",
       "        [ 5,  6,  7,  8, 10, 12, 14, 16],\n",
       "        [ 9, 10, 11, 12, 18, 20, 22, 24]],\n",
       "\n",
       "       [[21, 22, 23, 24, 42, 44, 46, 48],\n",
       "        [25, 26, 27, 28, 50, 52, 54, 56],\n",
       "        [29, 30, 31, 32, 58, 60, 62, 64]]])"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# again same as = np.dstack((array_example_1, array_example_2))\n",
    "\n",
    "np.dstack((array_example_1, array_example_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, np.concatenate can replicate the 3 stacking functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2000.,   40.,  365., ..., 2000., 1000., 2000.])"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what if inputs have same dimension but different shapes/elements\n",
    "# unlike stacking this is possible\n",
    "\n",
    "np.concatenate((lending_co_data_numeric[0,:], lending_co_data_numeric[:,0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Unique Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    np.unique() takes array as input\n",
    "    returns array with all unique values of first array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2000.,    40.,   365.,  3121.,  4241., 13621.],\n",
       "       [ 2000.,    40.,   365.,  3061.,  4171., 15041.],\n",
       "       [ 1000.,    40.,   365.,  2160.,  3280., 15340.],\n",
       "       ...,\n",
       "       [ 2000.,    40.,   365.,  4201.,  5001., 16600.],\n",
       "       [ 1000.,    40.,   365.,  2080.,  3320., 15600.],\n",
       "       [ 2000.,    40.,   365.,  4601.,  4601., 16600.]])"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load dataset\n",
    "\n",
    "lending_co_data_numeric = np.loadtxt(\"Lending-company-Numeric.csv\", delimiter = ',') \n",
    "lending_co_data_numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2870., -2550., -2450., ..., 52751., 54625., 64001.])"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# unique values of whole array sorted from low to high\n",
    "\n",
    "np.unique(lending_co_data_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 35.,  40.,  50., 125., 165.])"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# unique values of second column array sorted from low to high\n",
    "\n",
    "np.unique(lending_co_data_numeric[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['A1', 'A2', 'A3', 'AA1', 'B1', 'B2', 'B3', 'a1', 'a2', 'a3'],\n",
       "      dtype='<U3')"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if the values of the array are text, the unique function sorts them in \"alphabetical\" order by their ASCII codes. \n",
    "\n",
    "array_example = np.array([\"a1\", \"a3\",\"A1\",\"A3\",\"A3\",\"AA1\",\"B1\",\"A2\",\"B1\",\"A2\",\"B2\",\"B2\", \"B3\",\"a2\",\"a3\",\"B3\",\"B3\",\"a3\" ])\n",
    "np.unique(array_example)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 35.,  40.,  50., 125., 165.]),\n",
       " array([327,   0,   4,  19,  27]),\n",
       " array([  4, 567, 451,  19,   2]))"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unique -> returns the unique values within the array in increasing order\n",
    "# return_counts -> returns how many times each unique value appears in the array\n",
    "# return_index -> returns the index of the first encounter with each unique value\n",
    "\n",
    "np.unique(lending_co_data_numeric[:,1], return_counts = True, return_index = True)\n",
    "# confusingly index is 2nd array in results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
